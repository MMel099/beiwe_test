{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa387b5-98a2-497b-8844-8eaaa59af236",
   "metadata": {},
   "source": [
    "### Survey QC\n",
    "\n",
    "Last updated: 04/18/2025\n",
    "\n",
    "Summary: This data pipeline was developed out of a need for accurate survey adherence statistics for the Fucito group at Yale. The overarching goal is to identify two relevant figures, N and D. N, the numerator, is the count of *valid* surveys submitted. D, the denominator, is the count of *valid* surveys delivered. Emphasis on the *valid* - this is a culmination of several rules determined through discussions between the Fucito and Beiwe teams.   \n",
    "\n",
    "Requirements: The raw survey data, including both survey answers and timings, has already been downloaded to a directory \"raw_data\" (this can be modified). Furthermore, part 3b extracts information from the Survey Settings and Interventions files (available in the 'Edit this Study' section of the dashboard), so these should be up to date. Finally, part 3c of this script calls a Beiwe API, which requires a Keyring Studies file with valid access and secret keys. \n",
    "\n",
    "#### Part 1: Identifying Mismatched Files\n",
    "\n",
    "This section iterates through raw survey data (survey answers and survey timings) and identifies files that are missing their counterparts. Survey answers record the timing of the submission in the csv file name, while survey timings have a row of data at the very end indicating that the user performed a submission action. This script records all submission times according to survey answers and separately according to suvery timings. Then these times are cross-examined to determine missing or erroneous files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9cfdf-d97b-420f-8cd6-a9017070461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below and use it to install any necessary packages.\n",
    "#%pip install ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4865cd59-7743-40d2-b1f7-f04fe61f91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "import orjson\n",
    "import data_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0378c21b-242b-4443-b8f4-9ebd6b0cf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_submission_rows(file_path, survey_id):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the relative file path of the file to be examined\n",
    "        survey_id: the survey of interest \n",
    "    Outputs:\n",
    "        submission_time: a list containing UTC time strings of submission times, an empty list is returned if a submission row is not found\n",
    "    Behavior:\n",
    "        This function scans each survey timings file and gradually builds up the submission histories of users \n",
    "        by appending to the existing submission_dates object each time a submission row is identified\n",
    "    '''\n",
    "    with open(file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        result = []\n",
    "        # Iterate the file by row\n",
    "        for row in reader:\n",
    "            event_value = row.get('event', '').strip().lower()\n",
    "            question_id_value = row.get('question id', '').strip().lower()\n",
    "            curr_survey_id = row.get('survey id', '').strip()\n",
    "            # Check for a submission row and return the submission time if suitable\n",
    "            if (event_value == 'submitted' or question_id_value == 'user hit submit') and curr_survey_id == survey_id:\n",
    "                result.append(row.get('UTC time'))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b8d8a9-f132-45b7-abfc-752f6cf25b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_answer_files(survey_answers_dir, survey_id):\n",
    "    '''\n",
    "    Inputs:\n",
    "        survey_answers_dir: the relative file path of the survey answers directory\n",
    "        survey_id: the survey of interest \n",
    "    Outputs:\n",
    "        answers_submissions: a df containing submission times and corresponding file paths generated from answer files\n",
    "    Behavior:\n",
    "        This function iterates through all of the survey answer files in a specific survey directory and generate a df object \n",
    "        containing submission times and paths to the corresponding files\n",
    "    '''\n",
    "    answers_submissions = pd.DataFrame(columns=['Time', 'FilePath', 'Extension'])\n",
    "\n",
    "    # Check if the survey answers directory exists for specific survey id\n",
    "    survey_answers_survey_dir = os.path.join(survey_answers_dir, survey_id)\n",
    "    if os.path.isdir(survey_answers_survey_dir):\n",
    "        \n",
    "        # Iterate through survey answers files and gather their submission time via the file name\n",
    "        for file in os.listdir(survey_answers_survey_dir):\n",
    "            file_path = os.path.join(survey_answers_survey_dir, file)\n",
    "            submission_time = os.path.splitext(file)[0]\n",
    "            extension = os.path.splitext(file)[1]\n",
    "            new_submission = pd.DataFrame({ \n",
    "                'Time': [submission_time], \n",
    "                'FilePath': [file_path],\n",
    "                'Extension': [extension]\n",
    "            })\n",
    "            answers_submissions = pd.concat([answers_submissions, new_submission])\n",
    "            \n",
    "    # Process the 'Time' column into a standard format\n",
    "    answers_submissions['Time'] = answers_submissions['Time'].str.replace(\"_\", \":\", regex=False).str[:-6]\n",
    "    answers_submissions['Time'] = pd.to_datetime(answers_submissions['Time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Sort by 'Time' also ensuring that .csv files are prioritized\n",
    "    answers_submissions = answers_submissions.sort_values(by=[\"Time\", \"Extension\"], key=lambda col: col.map(lambda x: (x != '.csv', x)))\n",
    "    \n",
    "    return answers_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7068c58a-b512-44d3-a423-3e0209f76f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_timings_files(survey_timings_dir, survey_id):\n",
    "    '''\n",
    "    Inputs:\n",
    "        survey_timings_dir: the relative file path of the survey timings directory\n",
    "        survey_id: the survey of interest \n",
    "    Outputs:\n",
    "        timings_submissions: a df containing submission times and corresponding file paths generated from timings files\n",
    "    Behavior:\n",
    "        This function iterates through all of the survey timings files in a specific survey directory and generate a df object \n",
    "        containing submission times and paths to the corresponding files\n",
    "    '''\n",
    "    timings_submissions = pd.DataFrame(columns=['Time', 'FilePath'])\n",
    "\n",
    "    # Check if the survey timings directory exists for specific survey id\n",
    "    survey_timings_survey_dir = os.path.join(survey_timings_dir, survey_id)\n",
    "    if os.path.isdir(survey_timings_survey_dir):\n",
    "            \n",
    "        # Iterate through survey timings files and call extract_submission_rows function to identify submission times\n",
    "        for file in os.listdir(survey_timings_survey_dir):\n",
    "            file_path = os.path.join(survey_timings_survey_dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                result = extract_submission_rows(file_path, survey_id)\n",
    "                if result:\n",
    "                    new_submission = pd.DataFrame({\n",
    "                        'Time': result,\n",
    "                        'FilePath': [file_path] * len(result) \n",
    "                    })\n",
    "                    timings_submissions = pd.concat([timings_submissions, new_submission]) \n",
    "\n",
    "    # Process the 'Time' column into a standard format and sort by it\n",
    "    timings_submissions['Time'] = pd.to_datetime(timings_submissions['Time'], format=\"%Y-%m-%dT%H:%M:%S.%f\").dt.floor('s')\n",
    "    timings_submissions = timings_submissions.sort_values(by=\"Time\")\n",
    "    \n",
    "    return timings_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6525a342-b9ee-47fd-bd37-5e98f050c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_submission_logs(answers_submissions, timings_submissions):\n",
    "    '''\n",
    "    Inputs:\n",
    "        answers_submissions: a df containing submission times and corresponding file paths generated from answer files\n",
    "        timings_submissions: a df containing submission times and corresponding file paths generated from timings files\n",
    "    Outputs:\n",
    "        matched: a count of the number of matched files identified with the two given logs\n",
    "        unmatched: a count of the number of unmatched files identified with the two given logs\n",
    "    Behavior:\n",
    "        This function compares the answers and timings submission logs and flags any unmatched submission files\n",
    "    '''\n",
    "    # Initialize two index variables to traverse the logs and trackers of matched and unmatched files\n",
    "    answer_i = 0\n",
    "    timing_i = 0\n",
    "    matched = 0\n",
    "    unmatched = 0\n",
    "    \n",
    "    # Iterate through both lists at the same time looking for mismatches\n",
    "    while answer_i < answers_submissions.shape[0] and timing_i < timings_submissions.shape[0]:\n",
    "        time_diff = abs(answers_submissions['Time'].iloc[answer_i] - timings_submissions['Time'].iloc[timing_i])\n",
    "        # Allow an acceptable difference of 1 minute between submission times of answers and timings\n",
    "        if time_diff <= pd.Timedelta(minutes=1):\n",
    "            matched += 1\n",
    "            answer_i += 1\n",
    "            timing_i += 1\n",
    "            \n",
    "        # If differences larger than one minute are identified, there must be unmatched files\n",
    "        else:\n",
    "            if answers_submissions['Time'].iloc[answer_i] > timings_submissions['Time'].iloc[timing_i]:\n",
    "                print(f\"Unmatched file found at {timings_submissions['FilePath'].iloc[timing_i]}\")\n",
    "                unmatched += 1\n",
    "                timing_i += 1\n",
    "            else:\n",
    "                print(f\"Unmatched file found at {answers_submissions['FilePath'].iloc[answer_i]}\")\n",
    "                unmatched += 1\n",
    "                answer_i += 1\n",
    "\n",
    "    # Handle any remaining entries in either df\n",
    "    if answer_i < answers_submissions.shape[0]:\n",
    "        for index in range(answer_i, answers_submissions.shape[0]):\n",
    "            unmatched += 1\n",
    "            print(f\"Unmatched file found at {answers_submissions['FilePath'].iloc[index]}\")\n",
    "\n",
    "    if timing_i < timings_submissions.shape[0]:\n",
    "        for index in range(timing_i, timings_submissions.shape[0]):\n",
    "            unmatched += 1\n",
    "            print(f\"Unmatched file found at {timings_submissions['FilePath'].iloc[index]}\")\n",
    "\n",
    "    return matched, unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220a790a-73b6-41b0-ac0a-d9ae2ab52062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_unmatched_files(base_dir):\n",
    "    '''\n",
    "    Inputs:\n",
    "        base_dir: the directory containing the raw data\n",
    "    Behavior:\n",
    "        This function runs the compare_submission_logs function on all participants and surveys to identify all unmatched files\n",
    "    '''\n",
    "    # Initialize two variables for tracking total # of matched files and # of unmatched files\n",
    "    matched = 0\n",
    "    unmatched = 0\n",
    "    \n",
    "    # Iterate through each user_id directory\n",
    "    for user_id in os.listdir(base_dir):\n",
    "        user_dir = os.path.join(base_dir, user_id)\n",
    "            \n",
    "        if os.path.isdir(user_dir):\n",
    "            # Paths to the survey_timings and survey_answers directories\n",
    "            survey_timings_dir = os.path.join(user_dir, 'survey_timings')\n",
    "            survey_answers_dir = os.path.join(user_dir, 'survey_answers')\n",
    "                \n",
    "        # Check if the survey_timings directory exists and get the survey_ids\n",
    "        if os.path.exists(survey_timings_dir):\n",
    "            survey_timings_ids = set(os.listdir(survey_timings_dir))\n",
    "    \n",
    "        # Check if the survey_answers directory exists and get the survey_ids\n",
    "        if os.path.exists(survey_answers_dir):\n",
    "            survey_answers_ids = set(os.listdir(survey_answers_dir))\n",
    "    \n",
    "        # Get the union of survey ids from survey answers and timinigs\n",
    "        all_survey_ids = survey_timings_ids | survey_answers_ids\n",
    "            \n",
    "        # Iterate through each survey_id\n",
    "        for survey_id in all_survey_ids:\n",
    "    \n",
    "            # Call the iterator functions to look through the files and extract submission times\n",
    "            answers_submissions = iterate_answer_files(survey_answers_dir, survey_id)\n",
    "            timings_submissions = iterate_timings_files(survey_timings_dir, survey_id)\n",
    "    \n",
    "            # Call the comparison function to identify any unmatched survey files\n",
    "            temp_matched, temp_unmatched = compare_submission_logs(answers_submissions, timings_submissions)\n",
    "            matched += temp_matched\n",
    "            unmatched += temp_unmatched\n",
    "            \n",
    "    print(f\"Number of matched files identified: {matched}\")\n",
    "    print(f\"Number of unmatched files identified: {unmatched}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85857c94-859b-4f7b-84ff-6cd3ec59f333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched file found at raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-26 15_14_43+00_00.csv\n",
      "Unmatched file found at raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-05 14_28_04+00_00.csv\n",
      "Unmatched file found at raw_data/4ggpbwfj/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-05-27 14_30_38+00_00.csv\n",
      "Unmatched file found at raw_data/4ggpbwfj/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-06-17 20_04_05+00_00.csv\n",
      "Unmatched file found at raw_data/4ggpbwfj/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-05 14_26_05+00_00.csv\n",
      "Unmatched file found at raw_data/wihq7mla/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-25 13_02_04+00_00.csv\n",
      "Unmatched file found at raw_data/wihq7mla/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-26 13_22_45+00_00.csv\n",
      "Unmatched file found at raw_data/wihq7mla/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-23 14_57_13+00_00.csv\n",
      "Unmatched file found at raw_data/enylyud4/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 13_06_14+00_00.csv\n",
      "Unmatched file found at raw_data/enylyud4/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-24 23_15_42+00_00.csv\n",
      "Unmatched file found at raw_data/oy958u7q/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-15 20_19_38+00_00.csv\n",
      "Unmatched file found at raw_data/be3smgzk/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-08 18_05_07+00_00.csv\n",
      "Unmatched file found at raw_data/be3smgzk/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-09 18_57_22+00_00.csv\n",
      "Unmatched file found at raw_data/fhjswy1u/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-15 13_01_24+00_00.csv\n",
      "Unmatched file found at raw_data/1bllhfi7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-22 19_43_08+00_00.csv\n",
      "Unmatched file found at raw_data/1bllhfi7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-23 16_03_29+00_00.csv\n",
      "Unmatched file found at raw_data/1bllhfi7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-24 19_46_16+00_00.csv\n",
      "Unmatched file found at raw_data/1bllhfi7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-25 16_56_41+00_00.csv\n",
      "Unmatched file found at raw_data/1bllhfi7/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-16 16_26_15+00_00.csv\n",
      "Unmatched file found at raw_data/m58fpko8/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-25 16_50_04+00_00.csv\n",
      "Unmatched file found at raw_data/m58fpko8/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-26 22_09_23+00_00.csv\n",
      "Unmatched file found at raw_data/3xwxyr8p/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-07 22_43_47+00_00.csv\n",
      "Unmatched file found at raw_data/1anurea6/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-04 14_47_35+00_00.csv\n",
      "Unmatched file found at raw_data/l2jj4m6b/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 00_43_58+00_00.csv\n",
      "Unmatched file found at raw_data/k9meirtd/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 00_47_49+00_00.csv\n",
      "Unmatched file found at raw_data/xw35efiy/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-10-21 15_13_59+00_00.csv\n",
      "Unmatched file found at raw_data/chytqvef/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-23 17_04_08+00_00.csv\n",
      "Unmatched file found at raw_data/6d2sakpx/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-11 15_54_59+00_00.csv\n",
      "Unmatched file found at raw_data/boumgwee/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 14_40_47+00_00.csv\n",
      "Unmatched file found at raw_data/cshvodgb/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-23 21_35_35+00_00.csv\n",
      "Unmatched file found at raw_data/cshvodgb/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-01 04_51_25+00_00.csv\n",
      "Unmatched file found at raw_data/cshvodgb/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-31 01_57_22+00_00.csv\n",
      "Unmatched file found at raw_data/qtrph1ch/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-02-03 16_18_10+00_00.csv\n",
      "Unmatched file found at raw_data/tpr4b4hj/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-08-26 22_18_07+00_00.csv\n",
      "Unmatched file found at raw_data/x5n8ymny/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-05-10 01_55_39+00_00.csv\n",
      "Unmatched file found at raw_data/x5n8ymny/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-08 15_18_37+00_00.csv\n",
      "Unmatched file found at raw_data/srntczw7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-25 21_05_29+00_00.csv\n",
      "Unmatched file found at raw_data/srntczw7/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-03-21 23_51_48+00_00.csv\n",
      "Unmatched file found at raw_data/vis6vd5c/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-11 14_28_44+00_00.csv\n",
      "Unmatched file found at raw_data/l2e3gzih/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-15 17_39_27+00_00.csv\n",
      "Unmatched file found at raw_data/l2e3gzih/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-22 15_00_58+00_00.csv\n",
      "Unmatched file found at raw_data/l2e3gzih/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-03-19 20_03_51+00_00.csv\n",
      "Unmatched file found at raw_data/iwqpcimr/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-24 21_32_49+00_00.csv\n",
      "Unmatched file found at raw_data/acxdh2cq/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-19 00_22_57+00_00.csv\n",
      "Unmatched file found at raw_data/dlio244z/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 13_58_22+00_00.csv\n",
      "Unmatched file found at raw_data/dlio244z/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 13_08_36+00_00.csv\n",
      "Unmatched file found at raw_data/yo6y8jnx/survey_timings/PmZQCMHU8cAhIdZshFuipCPi/2024-01-29 21_00_00+00_00.csv\n",
      "Unmatched file found at raw_data/ly7qnqkp/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 00_49_16+00_00.csv\n",
      "Unmatched file found at raw_data/tbagwbl9/survey_timings/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 04_00_00+00_00.csv\n",
      "Unmatched file found at raw_data/wglu9o68/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-21 16_44_45+00_00.csv\n",
      "Unmatched file found at raw_data/o93nynue/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-13 19_42_37+00_00.csv\n",
      "Unmatched file found at raw_data/o93nynue/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-01-13 19_41_04+00_00.csv\n",
      "Unmatched file found at raw_data/ujhrk3b6/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-09-30 13_12_03+00_00.csv\n",
      "Unmatched file found at raw_data/sfih1cjt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-04 13_38_19+00_00.csv\n",
      "Unmatched file found at raw_data/sfih1cjt/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-29 13_00_37+00_00.csv\n",
      "Unmatched file found at raw_data/sfih1cjt/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-07 13_00_53+00_00.csv\n",
      "Unmatched file found at raw_data/sfih1cjt/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-29 01_28_28+00_00.csv\n",
      "Unmatched file found at raw_data/cvfd3sil/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-23 02_02_31+00_00.csv\n",
      "Unmatched file found at raw_data/cvfd3sil/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-23 16_28_51+00_00.csv\n",
      "Unmatched file found at raw_data/cvfd3sil/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-24 14_29_10+00_00.csv\n",
      "Unmatched file found at raw_data/cvfd3sil/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-26 01_19_59+00_00.csv\n",
      "Unmatched file found at raw_data/cvfd3sil/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-17 14_11_35+00_00.csv\n",
      "Unmatched file found at raw_data/cvfd3sil/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-06-17 14_10_11+00_00.csv\n",
      "Unmatched file found at raw_data/cvfd3sil/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-17 14_00_56+00_00.csv\n",
      "Unmatched file found at raw_data/nstx4ald/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 00_48_15+00_00.csv\n",
      "Unmatched file found at raw_data/wxokpxg8/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-02-07 00_57_37+00_00.csv\n",
      "Unmatched file found at raw_data/ttcznvyi/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-01-14 01_35_12+00_00.csv\n",
      "Unmatched file found at raw_data/6bgfd8eo/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-04 20_31_38+00_00.csv\n",
      "Unmatched file found at raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-07 18_18_03+00_00.csv\n",
      "Unmatched file found at raw_data/uiz2mt3n/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-11-07 18_18_03+00_00.csv\n",
      "Unmatched file found at raw_data/uiz2mt3n/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-11-08 00_13_45+00_00.csv\n",
      "Unmatched file found at raw_data/uiz2mt3n/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-11-08 00_13_46+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-01-18 22_27_00+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-07 14_08_06+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-05-14 17_24_59+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-12 20_12_50+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-01-18 22_15_36+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-02-06 16_24_59+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-05-14 17_26_02+00_00.csv\n",
      "Unmatched file found at raw_data/txo6lahs/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-07-12 20_11_21+00_00.csv\n",
      "Unmatched file found at raw_data/1f8ujz41/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-17 02_57_47+00_00.csv\n",
      "Unmatched file found at raw_data/bvavxgux/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-04 16_29_45+00_00.csv\n",
      "Unmatched file found at raw_data/h3pocaum/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 18_05_58+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2023-12-06 16_19_06+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2023-12-18 17_59_54+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2023-12-25 16_00_19+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-01-08 16_00_29+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-01-29 15_03_52+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-05 14_00_22+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-03 20_11_37+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-08 13_26_43+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-22 13_46_10+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-12 13_00_27+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-12 02_47_56+00_00.csv\n",
      "Unmatched file found at raw_data/gq4s82qs/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-30 20_36_08+00_00.csv\n",
      "Unmatched file found at raw_data/h6t5ke5r/survey_timings/PmZQCMHU8cAhIdZshFuipCPi/2025-03-19 00_00_00+00_00.csv\n",
      "Unmatched file found at raw_data/a2wiazls/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-18 17_19_47+00_00.csv\n",
      "Unmatched file found at raw_data/a2wiazls/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-03-18 17_05_53+00_00.csv\n",
      "Unmatched file found at raw_data/k98ncfwh/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-29 13_13_37+00_00.csv\n",
      "Unmatched file found at raw_data/k98ncfwh/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-11-05 20_00_57+00_00.csv\n",
      "Unmatched file found at raw_data/msj113qe/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-03 06_47_31+00_00.csv\n",
      "Unmatched file found at raw_data/msj113qe/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-01-03 06_41_22+00_00.csv\n",
      "Unmatched file found at raw_data/adwnelex/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-05 00_54_46+00_00.csv\n",
      "Unmatched file found at raw_data/eq3srjdy/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 01_38_15+00_00.csv\n",
      "Unmatched file found at raw_data/eq3srjdy/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 01_38_17+00_00.csv\n",
      "Unmatched file found at raw_data/eq3srjdy/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-12 15_18_27+00_00.csv\n",
      "Unmatched file found at raw_data/uewaotso/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-16 14_21_45+00_00.csv\n",
      "Unmatched file found at raw_data/y5vxfnxj/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-14 02_20_27+00_00.csv\n",
      "Unmatched file found at raw_data/y5vxfnxj/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-30 22_57_44+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-11 20_38_32+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-06 17_07_21+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 16_55_33+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 18_51_23+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 18_51_24+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 20_22_25+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 20_37_47+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 20_37_52+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 20_38_32+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 20_39_27+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-11 21_07_38+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 02_24_41+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 02_24_42+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 02_24_46+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 13_40_27+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 13_40_28+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 14_25_39+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 14_36_39+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 15_43_16+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 16_02_59+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 18_25_11+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 18_36_25+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 19_17_48+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 21_31_38+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 21_31_39+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 22_21_38+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-12 22_38_32+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 03_29_45+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 05_06_56+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 05_06_57+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 13_14_23+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 13_15_04+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 13_34_50+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 16_18_24+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 16_18_28+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 17_29_26+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 17_29_30+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 18_29_50+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 18_54_47+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 23_52_10+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-13 23_52_11+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-14 18_51_20+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-14 22_04_48+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-14 22_51_06+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 00_31_08+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 01_48_34+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 01_48_35+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 04_43_38+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 04_53_49+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 05_04_00+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 12_50_52+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 12_50_53+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 13_12_37+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 14_16_59+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 15_52_10+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 16_05_49+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 16_29_07+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 16_42_20+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 18_04_20+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 18_14_21+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 18_31_27+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 18_41_28+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 18_51_29+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 20_14_45+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 20_28_11+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-15 20_58_23+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-16 14_58_32+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-16 15_10_40+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-16 15_10_48+00_00.csv\n",
      "Unmatched file found at raw_data/ng7mkyit/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-10-16 16_08_38+00_00.csv\n",
      "Unmatched file found at raw_data/8wcv79ly/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-02-25 00_48_53+00_00.csv\n",
      "Unmatched file found at raw_data/s14yyl3j/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-01-05 12_17_42+00_00.csv\n",
      "Unmatched file found at raw_data/rstokk1a/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 00_53_44+00_00.csv\n",
      "Unmatched file found at raw_data/rstokk1a/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-09 15_05_09+00_00.csv\n",
      "Unmatched file found at raw_data/cbh8yze7/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 14_00_29+00_00.csv\n",
      "Unmatched file found at raw_data/89v1avmz/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 13_14_35+00_00.csv\n",
      "Unmatched file found at raw_data/89v1avmz/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-14 23_26_45+00_00.csv\n",
      "Unmatched file found at raw_data/6uqywzdm/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 14_13_51+00_00.csv\n",
      "Unmatched file found at raw_data/o72ugjhg/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-25 18_01_21+00_00.csv\n",
      "Unmatched file found at raw_data/o72ugjhg/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-28 11_21_22+00_00.csv\n",
      "Unmatched file found at raw_data/o72ugjhg/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-05 13_00_18+00_00.csv\n",
      "Unmatched file found at raw_data/o72ugjhg/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-15 16_31_27+00_00.csv\n",
      "Unmatched file found at raw_data/jeipst7r/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-26 20_51_08+00_00.csv\n",
      "Unmatched file found at raw_data/jeipst7r/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-16 13_45_09+00_00.csv\n",
      "Unmatched file found at raw_data/jeipst7r/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-02 17_56_43+00_00.csv\n",
      "Unmatched file found at raw_data/kc17pj4t/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-02-10 14_00_30+00_00.csv\n",
      "Unmatched file found at raw_data/29dam7cc/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-17 23_56_05+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-12 23_10_02+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-20 03_55_43+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-27 01_09_20+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-05 04_37_40+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-12 13_09_13+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-19 03_37_15+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-26 00_13_26+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-03 04_01_57+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-09 00_05_58+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-21 23_22_29+00_00.csv\n",
      "Unmatched file found at raw_data/ra5aq9d5/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-01-18 04_37_42+00_00.csv\n",
      "Unmatched file found at raw_data/ag5wdmi3/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-23 13_11_54+00_00.csv\n",
      "Unmatched file found at raw_data/1ib9r56g/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-01-30 05_06_35+00_00.csv\n",
      "Unmatched file found at raw_data/juqyd3vu/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-11 13_53_43+00_00.csv\n",
      "Unmatched file found at raw_data/juqyd3vu/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 14_13_25+00_00.csv\n",
      "Unmatched file found at raw_data/yd8makxv/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-18 22_51_55+00_00.csv\n",
      "Unmatched file found at raw_data/yd8makxv/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-25 13_02_48+00_00.csv\n",
      "Unmatched file found at raw_data/yd8makxv/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-01-18 22_50_27+00_00.csv\n",
      "Unmatched file found at raw_data/yd8makxv/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 13_00_33+00_00.csv\n",
      "Unmatched file found at raw_data/yd8makxv/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-23 13_49_05+00_00.csv\n",
      "Unmatched file found at raw_data/yd8makxv/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-23 14_00_36+00_00.csv\n",
      "Unmatched file found at raw_data/tl57unkl/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 17_42_25+00_00.csv\n",
      "Unmatched file found at raw_data/tl57unkl/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-08 13_02_01+00_00.csv\n",
      "Unmatched file found at raw_data/tl57unkl/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-02 20_35_05+00_00.csv\n",
      "Unmatched file found at raw_data/r8y71qnz/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-14 06_09_44+00_00.csv\n",
      "Unmatched file found at raw_data/r8y71qnz/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-03-03 21_31_54+00_00.csv\n",
      "Unmatched file found at raw_data/r8y71qnz/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-14 06_09_44+00_00.csv\n",
      "Unmatched file found at raw_data/r8y71qnz/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-03-03 21_31_54+00_00.csv\n",
      "Unmatched file found at raw_data/sfctppup/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-10-14 13_46_47+00_00.csv\n",
      "Unmatched file found at raw_data/sfctppup/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-15 20_26_36+00_00.csv\n",
      "Unmatched file found at raw_data/sfctppup/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-14 13_46_52+00_00.csv\n",
      "Unmatched file found at raw_data/4sl276dm/survey_timings/PmZQCMHU8cAhIdZshFuipCPi/2024-03-04 19_00_00+00_00.csv\n",
      "Unmatched file found at raw_data/ji6kggnh/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-25 17_37_33+00_00.csv\n",
      "Unmatched file found at raw_data/ji6kggnh/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-26 15_31_12+00_00.csv\n",
      "Unmatched file found at raw_data/ji6kggnh/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-05-13 17_26_18+00_00.csv\n",
      "Unmatched file found at raw_data/qxgs5tdn/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-22 20_04_31+00_00.csv\n",
      "Unmatched file found at raw_data/qxgs5tdn/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-02 02_05_56+00_00.csv\n",
      "Unmatched file found at raw_data/qxgs5tdn/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-06-12 01_31_10+00_00.csv\n",
      "Unmatched file found at raw_data/qxgs5tdn/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-10 19_00_16+00_00.csv\n",
      "Unmatched file found at raw_data/fxc99971/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-11-25 19_20_28+00_00.csv\n",
      "Unmatched file found at raw_data/4qg4ghee/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-18 14_26_42+00_00.csv\n",
      "Unmatched file found at raw_data/4qg4ghee/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-12 13_31_48+00_00.csv\n",
      "Unmatched file found at raw_data/6yq7anur/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-05-19 23_15_44+00_00.csv\n",
      "Unmatched file found at raw_data/hoqafprw/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-11 19_29_50+00_00.csv\n",
      "Unmatched file found at raw_data/hoqafprw/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-11 19_28_37+00_00.csv\n",
      "Unmatched file found at raw_data/hoqafprw/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-10 02_54_11+00_00.csv\n",
      "Unmatched file found at raw_data/hoqafprw/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-02-17 16_05_45+00_00.csv\n",
      "Unmatched file found at raw_data/hoqafprw/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-08-12 20_50_57+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-05 14_11_00+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-12 14_06_33+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-19 14_33_48+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-26 14_09_12+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-04 14_02_46+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-11 13_05_01+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-18 13_02_23+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 13_03_27+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 13_05_49+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-01 13_07_57+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-08 13_19_05+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-15 13_12_20+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-15 13_13_20+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-15 13_18_49+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-16 09_22_21+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-16 11_24_18+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-17 20_33_58+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-05-06 13_01_59+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-06-24 13_02_28+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-15 13_12_11+00_00.csv\n",
      "Unmatched file found at raw_data/mhwnmw12/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-01-12 22_11_51+00_00.csv\n",
      "Unmatched file found at raw_data/f1xqtpld/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-09 14_00_35+00_00.csv\n",
      "Unmatched file found at raw_data/pewlnfhy/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-20 19_12_38+00_00.csv\n",
      "Unmatched file found at raw_data/j96jck8o/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-18 01_52_10+00_00.csv\n",
      "Unmatched file found at raw_data/j96jck8o/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-06-18 01_43_40+00_00.csv\n",
      "Unmatched file found at raw_data/j96jck8o/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-22 02_17_51+00_00.csv\n",
      "Unmatched file found at raw_data/rz1t9mpt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-20 19_12_24+00_00.csv\n",
      "Unmatched file found at raw_data/rz1t9mpt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-14 23_22_09+00_00.csv\n",
      "Unmatched file found at raw_data/rz1t9mpt/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-15 19_25_06+00_00.csv\n",
      "Unmatched file found at raw_data/rz1t9mpt/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-10-15 19_22_45+00_00.csv\n",
      "Unmatched file found at raw_data/6471v7gr/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-07 17_05_43+00_00.csv\n",
      "Unmatched file found at raw_data/skv7wklf/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2023-11-07 04_09_47+00_00.csv\n",
      "Unmatched file found at raw_data/js9dzj4m/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-16 17_01_20+00_00.csv\n",
      "Unmatched file found at raw_data/qlltcvsd/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-20 21_08_04+00_00.csv\n",
      "Unmatched file found at raw_data/slgm2rxi/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-17 05_24_56+00_00.csv\n",
      "Unmatched file found at raw_data/slgm2rxi/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-07 01_07_59+00_00.csv\n",
      "Unmatched file found at raw_data/8hszphf9/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-03 19_07_42+00_00.csv\n",
      "Unmatched file found at raw_data/8hszphf9/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-06-03 19_01_09+00_00.csv\n",
      "Unmatched file found at raw_data/ter7pxoe/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-08-19 21_42_24+00_00.csv\n",
      "Unmatched file found at raw_data/ter7pxoe/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-19 15_44_02+00_00.csv\n",
      "Unmatched file found at raw_data/vx8o93mc/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 00_44_01+00_00.csv\n",
      "Unmatched file found at raw_data/ubeks4fp/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-01 00_52_50+00_00.csv\n",
      "Unmatched file found at raw_data/ubeks4fp/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-31 22_02_45+00_00.csv\n",
      "Unmatched file found at raw_data/m9x9l5rj/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 12_08_15+00_00.csv\n",
      "Unmatched file found at raw_data/mjumw9e3/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-13 00_52_09+00_00.csv\n",
      "Unmatched file found at raw_data/mjumw9e3/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-19 05_11_50+00_00.csv\n",
      "Unmatched file found at raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-23 14_50_24+00_00.csv\n",
      "Unmatched file found at raw_data/6qmqfkeq/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-15 00_59_04+00_00.csv\n",
      "Unmatched file found at raw_data/ctp8953m/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-02-17 23_31_36+00_00.csv\n",
      "Unmatched file found at raw_data/1w8gybjj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-03 15_32_45+00_00.csv\n",
      "Unmatched file found at raw_data/1w8gybjj/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-11-25 18_25_04+00_00.csv\n",
      "Unmatched file found at raw_data/1w8gybjj/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-02-03 15_32_50+00_00.csv\n",
      "Unmatched file found at raw_data/xigutsxt/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-10-07 15_11_34+00_00.csv\n",
      "Unmatched file found at raw_data/xigutsxt/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-07 20_45_32+00_00.csv\n",
      "Unmatched file found at raw_data/9ehmj2fz/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-16 05_58_19+00_00.csv\n",
      "Unmatched file found at raw_data/9ehmj2fz/survey_answers/jQdZNFQbIhTOOrYO9bS4sQcr/2025-03-16 05_58_23+00_00.csv\n",
      "Unmatched file found at raw_data/4ahuk17u/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-23 22_30_00+00_00.csv\n",
      "Unmatched file found at raw_data/4ahuk17u/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-12-24 00_01_55+00_00.csv\n",
      "Unmatched file found at raw_data/e15hkfui/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-15 13_06_55+00_00.csv\n",
      "Unmatched file found at raw_data/e15hkfui/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-04-22 13_36_01+00_00.csv\n",
      "Unmatched file found at raw_data/e15hkfui/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-03-18 13_44_58+00_00.csv\n",
      "Unmatched file found at raw_data/tkwn9148/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-02-29 04_12_46+00_00.csv\n",
      "Unmatched file found at raw_data/tkwn9148/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-15 14_04_59+00_00.csv\n",
      "Unmatched file found at raw_data/tkwn9148/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-09-30 07_37_09+00_00.csv\n",
      "Unmatched file found at raw_data/iadeeya3/survey_timings/PmZQCMHU8cAhIdZshFuipCPi/2024-02-02 18_00_00+00_00.csv\n",
      "Unmatched file found at raw_data/iadeeya3/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2023-12-25 14_13_10+00_00.csv\n",
      "Unmatched file found at raw_data/iadeeya3/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-01-05 17_40_03+00_00.csv\n",
      "Unmatched file found at raw_data/iadeeya3/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-09 14_06_47+00_00.csv\n",
      "Unmatched file found at raw_data/iadeeya3/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-07-11 20_07_00+00_00.csv\n",
      "Unmatched file found at raw_data/d188d2ib/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-03-25 16_55_00+00_00.csv\n",
      "Unmatched file found at raw_data/6c5fwr29/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-22 21_21_34+00_00.csv\n",
      "Unmatched file found at raw_data/6c5fwr29/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2024-05-22 21_19_58+00_00.csv\n",
      "Unmatched file found at raw_data/6c5fwr29/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2024-05-22 21_20_13+00_00.csv\n",
      "Unmatched file found at raw_data/81jervii/survey_answers/9A3eA4U3kFK7ICiYMkPb352v/2025-01-21 17_23_49+00_00.csv\n",
      "Unmatched file found at raw_data/rcmc2dws/survey_answers/HQX9l8EPfc578Saxj9zZJOZC/2025-02-16 13_01_23+00_00.csv\n",
      "Unmatched file found at raw_data/h323v5fd/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-29 14_20_35+00_00.csv\n",
      "Unmatched file found at raw_data/h323v5fd/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-26 15_10_13+00_00.csv\n",
      "Number of matched files identified: 8258\n",
      "Number of unmatched files identified: 321\n"
     ]
    }
   ],
   "source": [
    "# This command deletes any .ipynb_checkpoints which can interfere with file iteration\n",
    "!rm -rf $(find . -type d -name .ipynb_checkpoints)\n",
    "\n",
    "base_dir = \"raw_data\"\n",
    "identify_unmatched_files(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c98987-c463-4e55-997e-439090371587",
   "metadata": {},
   "source": [
    "#### Part 2: Identifying Duplicate Answers\n",
    "\n",
    "This section traverses through each participant's survey answers data and identifies duplicate files using MD5 hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f94fcc-7adb-4815-896c-53e0d4b3fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_file_contents(file_path):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the file path of the file to be hashed\n",
    "    Behavior:\n",
    "        This function reads a csv file and hashed it into a 32 character string that can help identify duplicates\n",
    "    '''\n",
    "    import hashlib\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as file:\n",
    "        buf = file.read()\n",
    "        hasher.update(buf)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def identify_duplicate_answers (base_dir, target_survey_id=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        base_dir: the name of the directory containing the raw data\n",
    "        target_survey_id: the survey ID to check for duplicate answers, if None it checks all surveys.\n",
    "    Behavior:\n",
    "        This function compares all the survey answer files of a specified survey within each participant and identifies any duplicates\n",
    "    '''\n",
    "\n",
    "    # Initialize a dictionary to store all hashes\n",
    "    all_hashes = {}\n",
    "    \n",
    "    # Iterate through each user_id directory\n",
    "    for user_id in os.listdir(base_dir):\n",
    "        user_dir = os.path.join(base_dir, user_id)\n",
    "        \n",
    "        if os.path.isdir(user_dir):\n",
    "            # Path to the survey_answers directory\n",
    "            survey_answers_dir = os.path.join(user_dir, 'survey_answers')\n",
    "            \n",
    "            # Check if the survey_answers directory exists\n",
    "            if os.path.exists(survey_answers_dir):\n",
    "                # Get the survey_ids to check\n",
    "                if target_survey_id:\n",
    "                    survey_ids_to_check = [target_survey_id]\n",
    "                else:\n",
    "                    survey_ids_to_check = os.listdir(survey_answers_dir)\n",
    "                \n",
    "                # Iterate through each survey_id\n",
    "                for survey_id in survey_ids_to_check:\n",
    "                    # Path to the specific survey_id directory\n",
    "                    survey_answers_survey_dir = os.path.join(survey_answers_dir, survey_id)\n",
    "                    \n",
    "                    if os.path.isdir(survey_answers_survey_dir):\n",
    "                        # Gather all .csv file paths in the directory\n",
    "                        file_paths = [\n",
    "                            os.path.join(survey_answers_survey_dir, file)\n",
    "                            for file in os.listdir(survey_answers_survey_dir)\n",
    "                            if os.path.isfile(os.path.join(survey_answers_survey_dir, file)) and file.endswith('.csv')\n",
    "                        ]\n",
    "                        \n",
    "                        # Maintain a dictionary to track duplicates\n",
    "                        for file_path in file_paths:\n",
    "                            # Generate hash of the file contents\n",
    "                            file_hash = hash_file_contents(file_path)\n",
    "                            if file_hash in all_hashes:\n",
    "                                all_hashes[file_hash].append(file_path)\n",
    "                            else:\n",
    "                                all_hashes[file_hash] = [file_path]\n",
    "\n",
    "    duplicates_output = []\n",
    "    \n",
    "    # Prepare duplicate groups for output\n",
    "    for file_group in all_hashes.values():\n",
    "        if len(file_group) > 1:\n",
    "            joined_paths = \"\\n\".join(file_group)\n",
    "            # Print duplicates to the console\n",
    "            print(f\"Duplicate files found:\\n{joined_paths}\\n\")\n",
    "            duplicates_output.append(f\"Duplicate files found:\\n{joined_paths}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b4586f-020b-41dd-a9eb-df57e50b0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_duplicate_answers(base_dir, target_survey_id=\"PmZQCMHU8cAhIdZshFuipCPi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666eb8f0-d430-4a78-ab90-12dc039fe0ab",
   "metadata": {},
   "source": [
    "#### Part 3: Identifying Unexpected Submissions\n",
    "\n",
    "This section of the script attempts to flag any instances of *unexpected* survey submissions. There are two categories of submissions that have been deemed *unexpected*: multiple submissions for any 24-hour period$^1$, and submissions outside of the designated survey periods. \n",
    "\n",
    "$^1$Eligible submission periods may be less than 24 hours based on the deployment of the next survey iteration.\n",
    "\n",
    "##### Part 3a: Generating a Log of Answers\n",
    "\n",
    "The first task is to generate a log of all survey answers for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "703c2682-b1ae-4d30-a191-7ee8425fe675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers_log(base_dir, survey_id=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        base_dir: the directory containing the raw data\n",
    "        survey_id: the survey_id to be filtered, if none is specified, all surveys are considered\n",
    "    Output:\n",
    "        full_log: the df object containing all submission dates and filepaths for each user\n",
    "    Behavior:\n",
    "        This function iterates through all users and generates one large object filled with \n",
    "        information about participants' survey answer times\n",
    "    '''\n",
    "    # Generate a df object to hold all submission times for participants\n",
    "    full_log = pd.DataFrame(columns=['BeiweID', 'Date', 'TimestampUTC', 'FilePath'])\n",
    "\n",
    "    # Iterate through each user_id directory\n",
    "    for user_id in os.listdir(base_dir):\n",
    "        user_dir = os.path.join(base_dir, user_id)\n",
    "            \n",
    "        if os.path.isdir(user_dir):\n",
    "            # Paths to the survey_answers directorie\n",
    "            survey_answers_dir = os.path.join(user_dir, 'survey_answers')\n",
    "    \n",
    "        # Check if the survey_answers directory exists and get the survey_ids\n",
    "        if os.path.exists(survey_answers_dir):\n",
    "            survey_answers_ids = set(os.listdir(survey_answers_dir))\n",
    "\n",
    "        # Only consider specified survey_id\n",
    "        if survey_id is not None:\n",
    "    \n",
    "            # Call the iterator functions to look through the files and extract submission times\n",
    "            answers_submissions = iterate_answer_files(survey_answers_dir, survey_id)\n",
    "            answers_submissions = answers_submissions[answers_submissions['Extension'] == \".csv\"]\n",
    "\n",
    "            # Add the new submissions to the existing log\n",
    "            new_submission = pd.DataFrame({\n",
    "                'BeiweID': [user_id] * len(answers_submissions),\n",
    "                'Date': answers_submissions['Time'].dt.date,\n",
    "                'TimestampUTC': answers_submissions['Time'],\n",
    "                'FilePath': answers_submissions['FilePath']\n",
    "            })\n",
    "            full_log = pd.concat([full_log, new_submission]) \n",
    "        \n",
    "        else:\n",
    "            # Iterate through each survey\n",
    "            for survey in survey_answers_ids:\n",
    "\n",
    "                # Call the iterator functions to look through the files and extract submission times\n",
    "                answers_submissions = iterate_answer_files(survey_answers_dir, survey)\n",
    "                answers_submissions = answers_submissions[answers_submissions['Extension'] == \".csv\"]\n",
    "\n",
    "                # Add the new submissions to the existing log\n",
    "                new_submission = pd.DataFrame({\n",
    "                    'BeiweID': [user_id] * len(answers_submissions),\n",
    "                    'Date': answers_submissions['Time'].dt.date,\n",
    "                    'TimestampUTC': answers_submissions['Time'],\n",
    "                    'FilePath': answers_submissions['FilePath']\n",
    "                })\n",
    "                full_log = pd.concat([full_log, new_submission])\n",
    "                \n",
    "    full_log = full_log.sort_values(by=[\"BeiweID\", \"TimestampUTC\"])\n",
    "    return full_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29c049b-a01e-4559-9ac5-b81233561ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/q6vckqdx64v8bb5_y2dtjvjw0000gn/T/ipykernel_43386/3034119563.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_log = pd.concat([full_log, new_submission])\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $(find . -type f -name .DS_Store)\n",
    "base_dir = \"raw_data\"\n",
    "log = generate_answers_log(base_dir, survey_id=\"PmZQCMHU8cAhIdZshFuipCPi\")\n",
    "log.to_csv('answers_log_full.csv', index=False)\n",
    "\n",
    "# Generate a csv containing Beiwe IDs and their survey submission counts\n",
    "counts = log.groupby('BeiweID').size()\n",
    "counts = counts.reset_index(name='SurveyCount')\n",
    "counts.to_csv('final_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29a619-2ada-4b46-a909-e0c84844d8d8",
   "metadata": {},
   "source": [
    "##### Part 3b: Generating an Expected Schedule\n",
    "\n",
    "Next, we need to generate an expected schedule of diary notifications based on participants' enrollment dates and the diary relative schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34610f29-0c3a-446d-8062-a0f27bd61440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_interventions_file(file_path):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the path to the interventions json\n",
    "    Output:\n",
    "        enrollment_log: the df object containing every participant's enrollement date\n",
    "    Behavior:\n",
    "        This function looks through the interventions json to determine enrollment dates for all participants. \n",
    "        THIS FUNCTION NEEDS TO BE CUSTOMIZED TO A SPECIFIC STUDY.\n",
    "    '''\n",
    "    # Initialize an empty list to hold user data\n",
    "    enrollment_log = []\n",
    "\n",
    "    # Read the interventions json file\n",
    "    with open(file_path, 'r') as file:\n",
    "        interventions = json.load(file)\n",
    "        # Iterate for each individual\n",
    "        for user in interventions:\n",
    "            user_data = interventions[user]\n",
    "            key = next(iter(user_data.keys()))\n",
    "            # Record the Beiwe ID and enrollment date of the individual\n",
    "            enrollment_log.append({\n",
    "                'BeiweID': user,\n",
    "                'EnrollmentDate': user_data[key]['Enrollment date']\n",
    "            })\n",
    "    return pd.DataFrame(enrollment_log)\n",
    "\n",
    "def read_settings_file(file_path):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the path to the settings json\n",
    "    Output:\n",
    "        notification_days: a list containing the relative deployment dates from the enrollment date\n",
    "    Behavior:\n",
    "        This function looks through the settings json to determine which relative dates the diary survey is deployed on.\n",
    "        THIS FUNCTION NEEDS TO BE CUSTOMIZED TO A SPECIFIC STUDY.\n",
    "    '''\n",
    "    # Initialize an empty list to hold user data\n",
    "    notification_days = []\n",
    "\n",
    "    # Read the settings json file\n",
    "    with open(file_path, 'r') as file:\n",
    "        settings = json.load(file)\n",
    "        # Access the relative schedule of the Diary survey\n",
    "        timings = settings['surveys'][6]['relative_timings']\n",
    "        for timing in timings:\n",
    "            # Record the relative deployment day of the survey\n",
    "            notification_days.append(timing[1])\n",
    "\n",
    "    notification_days.sort()\n",
    "    return notification_days\n",
    "\n",
    "def generate_expected_survey_schedule():\n",
    "    '''\n",
    "    Output:\n",
    "        full_schedule: the df object containing all expected notification dates for all participants\n",
    "    Behavior:\n",
    "        This function calls the two methods above to look through study jsons and then generates an \n",
    "        expected survey schedule for each participant\n",
    "    '''\n",
    "    # Gather enrollment data from the intervention file\n",
    "    interventions_file = \"m4z54N5SU7Eqq2LbwmxQd2UN_intervention_data.json\"\n",
    "    interventions = read_interventions_file(interventions_file)\n",
    "\n",
    "    # Gather scheduling data using the settings file\n",
    "    settings_file = \"Yale_Fucito_Young_Adult_Alcohol_-_Live_Study_surveys_and_settings.json\"\n",
    "    settings = read_settings_file(settings_file)\n",
    "\n",
    "    # Initiate a new list to track the full expected schedule of surveys for all participants\n",
    "    full_schedule = []\n",
    "    # Iterate for each pariticipant\n",
    "    for index, row in interventions.iterrows():\n",
    "        # Extract the Beiwe ID and enrollment date\n",
    "        enrollment_date = pd.Timestamp(row['EnrollmentDate'])\n",
    "        beiwe_id = row['BeiweID']\n",
    "\n",
    "        # Iterate for each deployment day of the Diary relative schedule\n",
    "        for day in settings:\n",
    "            # Calculate the absolute date of the deployment\n",
    "            new_date = enrollment_date + timedelta(days=day)\n",
    "            burst = day // 90 + 1\n",
    "            # Record this absolute date\n",
    "            full_schedule.append({\n",
    "                'BeiweID': beiwe_id,\n",
    "                'EnrollmentDate': enrollment_date,\n",
    "                'RelativeDay': day,\n",
    "                'Burst': burst,\n",
    "                'CalculatedDate': new_date\n",
    "            })\n",
    "            \n",
    "    full_schedule = pd.DataFrame(full_schedule)\n",
    "    full_schedule = full_schedule.sort_values(by=[\"BeiweID\", \"RelativeDay\"])\n",
    "    return full_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "566f05fe-07fb-4187-a34a-5797c66b88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_expected_survey_schedule()\n",
    "dates.to_csv('notification_dates_log.csv', index=False)\n",
    "\n",
    "# Update final counts csv with enrollment dates and final survey dates\n",
    "counts = pd.read_csv(\"final_counts.csv\")\n",
    "last_dates = dates.groupby('BeiweID').last().reset_index()\n",
    "counts = counts.merge(\n",
    "            last_dates[['BeiweID', 'EnrollmentDate', 'CalculatedDate']],\n",
    "            how='left',\n",
    "            left_on=['BeiweID'],\n",
    "            right_on=['BeiweID']\n",
    "        )\n",
    "counts.rename(columns={'CalculatedDate': 'LastSurvey'}, inplace=True)\n",
    "counts.to_csv('final_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a4dc3-3d3f-4809-905e-ae773071369c",
   "metadata": {},
   "source": [
    "##### Part 3c: Extracting Notification Times\n",
    "\n",
    "Using the notification API we can determine the absolute timings of survey notifications (which is important because deployments are localized to the participant's timezone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76762ab2-6097-4287-b711-2e6597a62052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_notifications_api(beiwe_id, access_key, secret_key):\n",
    "    '''\n",
    "    Inputs:\n",
    "        beiwe_id: the user whose notification history to access\n",
    "        access_key: API access key from the keyring file\n",
    "        secret_key: API secret key from the keyring file \n",
    "    Output:\n",
    "        notification_history: a df containing the participant's notification deployment history for the Diary survey\n",
    "    Behavior:\n",
    "        This function calls the notification API to get a specific participant's notification history.\n",
    "        The API object is then converted into a df and filtered for original deployments of Diary surveys.\n",
    "    '''\n",
    "\n",
    "    # Make a post request to the get-participant-notification-history/v1 endpoint, including the api key,\n",
    "    # secret key, and participant_id as post parameters.\n",
    "    endpoint = \"https://studies.beiwe.org/get-participant-notification-history/v1\"\n",
    "    t_start = datetime.now()\n",
    "    print(\"Starting request at\", t_start, flush=True)\n",
    "    response = requests.post(\n",
    "        endpoint,\n",
    "        \n",
    "        # refine your parameters here\n",
    "        data={\n",
    "            \"participant_id\": beiwe_id,\n",
    "            \"access_key\": access_key,\n",
    "            \"secret_key\": secret_key           \n",
    "        },\n",
    "        allow_redirects=False,\n",
    "    )\n",
    "    t_end = datetime.now()\n",
    "    print(\"Request completed at\", t_end.isoformat(), \"duration:\", (t_end - t_start).total_seconds(), \"seconds\")\n",
    "    \n",
    "    status_code = response.status_code\n",
    "    raw_output = response.content\n",
    "    \n",
    "    # Sanity checking to make sure the request worked\n",
    "    print(\"http status code:\", response.status_code)\n",
    "    \n",
    "    assert status_code != 400, \\\n",
    "        \"400 usually means you are missing a required parameter, or something critical isn't passing some checks.\\n\" \\\n",
    "        \"Check your access key and secret key, if there is a study id make sure it is 24 characters long.\"\n",
    "    \n",
    "    assert status_code != 403, \\\n",
    "        \"Permissions Error, you are not authenticated to view data on this study.\"\n",
    "    \n",
    "    assert status_code != 404, \\\n",
    "        \"404 means that the entity you have specified does not exist. Check details like study_id, patient_id, etc.\"\n",
    "    \n",
    "    assert response.status_code != 301, \\\n",
    "        \"Encountered HTTP redirect, you may have forgotten the s in https. first 100 bytes of response:\\n\" \\\n",
    "        f\"{raw_output[:100]}\"\n",
    "    \n",
    "    assert response.content != b\"\", \"No data was returned by the server...\"\n",
    "    \n",
    "    print(\"Testing whether it is valid json...\")\n",
    "    try:\n",
    "        json_response = orjson.loads(response.content)\n",
    "        print(\"JSON successfully loadded into variable `json_response`\")\n",
    "    except orjson.JSONDecodeError:\n",
    "        print(\"Not valid JSON - which may or may not be an issue! Here is the raw output of the first 100 bytes:\")\n",
    "        print(raw_output[:100])\n",
    "        json_response = None\n",
    "\n",
    "    try:\n",
    "        # Filter out notifications for non-Diary surveys and resends/non-relative deployments\n",
    "        notifications_data = json_normalize(json_response['PmZQCMHU8cAhIdZshFuipCPi'])\n",
    "        notifications_data = notifications_data[(notifications_data['type'] == 'relative') & (~notifications_data['resend'])]\n",
    "        \n",
    "        # Create new columns for Beiwe ID, the date and the UTC time of delivery\n",
    "        notifications_data['id'] = beiwe_id\n",
    "        notifications_data['date'] = notifications_data['scheduled_time'].apply(lambda x: x.split('T')[0])\n",
    "        notifications_data['timestamp_UTC'] = notifications_data['timestamp'].apply(lambda x: pd.to_datetime(x, utc=True))\n",
    "        notifications_data['timestamp_UTC'] = notifications_data['timestamp_UTC'].dt.tz_convert(None)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {str(e)} - The expected key wasn't found in the API response.\")\n",
    "        return pd.DataFrame(columns=['id','date', 'timestamp_UTC'])\n",
    "    return notifications_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9fbe9b-bd11-4a27-9577-e43c0dc95183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_notifications_to_schedule(notification_dates_file):\n",
    "    '''\n",
    "    Inputs:\n",
    "        notification_dates_file: the csv file containing the expected notification schedule, as generated in Part 3b\n",
    "    Output:\n",
    "        notification_log: a df containing everything in the notification_dates_file with added columns for \n",
    "        delivery times and truncation times (end of that deployment's eligible submission period)\n",
    "    Behavior:\n",
    "        This function adds information about delivery times from the notification API to the notification schedule file\n",
    "    '''\n",
    "    # Read the notification_dates_file, convert it into a df and initialize new columns\n",
    "    schedule = pd.read_csv(notification_dates_file)\n",
    "    schedule['timestamp_UTC'] = None\n",
    "    \n",
    "    # Extract the unique users from this file\n",
    "    users = schedule['BeiweID'].unique()\n",
    "    \n",
    "    # Read the keyring_studies file to get the API access and secret keys\n",
    "    kr = data_summaries.read_keyring(\"keyring_studies.py\")\n",
    "    access_key = kr.get(\"ACCESS_KEY\")\n",
    "    secret_key = kr.get(\"SECRET_KEY\")\n",
    "\n",
    "    # Iterate for all users\n",
    "    for user in users:\n",
    "        # Collect the user's notification history\n",
    "        notifications_data = call_notifications_api(user, access_key, secret_key)\n",
    "\n",
    "        # Update the schedule df with the notification history\n",
    "        updated_schedule = schedule.merge(\n",
    "            notifications_data[['id','date', 'timestamp_UTC']],\n",
    "            how='left',\n",
    "            left_on=['BeiweID','CalculatedDate'],\n",
    "            right_on=['id','date']\n",
    "        )\n",
    "        schedule.loc[schedule['BeiweID'] == user, 'timestamp_UTC'] = updated_schedule['timestamp_UTC_y']\n",
    "\n",
    "    # Rename the timestamp column and add a column for the end of the survey's eligible period \n",
    "    schedule = schedule.rename(columns={'timestamp_UTC': 'DeliveredUTC'})\n",
    "    schedule['TruncatedUTC'] = schedule['DeliveredUTC'] + timedelta(hours=24)\n",
    "\n",
    "    for i in range(len(schedule) - 1):  \n",
    "        if schedule['BeiweID'].iloc[i] == schedule['BeiweID'].iloc[i + 1]:\n",
    "            current_truncated = schedule['TruncatedUTC'].iloc[i]\n",
    "            next_delivered = schedule['DeliveredUTC'].iloc[i + 1]\n",
    "            \n",
    "            if pd.notna(current_truncated) and pd.notna(next_delivered):\n",
    "                schedule.at[schedule.index[i], 'TruncatedUTC'] = min(current_truncated, next_delivered)\n",
    "\n",
    "    return schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5becabb7-c1f5-47c2-8032-9eb01d745cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting request at 2025-04-18 16:53:17.308693\n",
      "Request completed at 2025-04-18T16:53:17.690086 duration: 0.381393 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:17.722619\n",
      "Request completed at 2025-04-18T16:53:18.022895 duration: 0.300276 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:18.057073\n",
      "Request completed at 2025-04-18T16:53:18.365979 duration: 0.308906 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:18.402184\n",
      "Request completed at 2025-04-18T16:53:18.690975 duration: 0.288791 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:18.713146\n",
      "Request completed at 2025-04-18T16:53:19.019715 duration: 0.306569 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:19.054288\n",
      "Request completed at 2025-04-18T16:53:19.332265 duration: 0.277977 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:19.354962\n",
      "Request completed at 2025-04-18T16:53:19.633092 duration: 0.27813 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:19.655151\n",
      "Request completed at 2025-04-18T16:53:19.996504 duration: 0.341353 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:20.025812\n",
      "Request completed at 2025-04-18T16:53:20.299394 duration: 0.273582 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:20.325433\n",
      "Request completed at 2025-04-18T16:53:20.617326 duration: 0.291893 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:20.647777\n",
      "Request completed at 2025-04-18T16:53:20.911399 duration: 0.263622 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:20.932936\n",
      "Request completed at 2025-04-18T16:53:21.269138 duration: 0.336202 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:21.296743\n",
      "Request completed at 2025-04-18T16:53:21.556446 duration: 0.259703 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:21.587191\n",
      "Request completed at 2025-04-18T16:53:21.879887 duration: 0.292696 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:21.910738\n",
      "Request completed at 2025-04-18T16:53:22.174762 duration: 0.264024 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:22.198527\n",
      "Request completed at 2025-04-18T16:53:22.553669 duration: 0.355142 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:22.587373\n",
      "Request completed at 2025-04-18T16:53:22.879478 duration: 0.292105 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:22.907275\n",
      "Request completed at 2025-04-18T16:53:23.338804 duration: 0.431529 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:23.360634\n",
      "Request completed at 2025-04-18T16:53:23.649107 duration: 0.288473 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:23.679549\n",
      "Request completed at 2025-04-18T16:53:23.970168 duration: 0.290619 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:24.001795\n",
      "Request completed at 2025-04-18T16:53:24.337807 duration: 0.336012 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:24.370939\n",
      "Request completed at 2025-04-18T16:53:24.734791 duration: 0.363852 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:24.768865\n",
      "Request completed at 2025-04-18T16:53:25.096377 duration: 0.327512 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:25.122625\n",
      "Request completed at 2025-04-18T16:53:25.410446 duration: 0.287821 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:25.435406\n",
      "Request completed at 2025-04-18T16:53:25.700890 duration: 0.265484 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:53:25.708821\n",
      "Request completed at 2025-04-18T16:53:26.034631 duration: 0.32581 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:26.070471\n",
      "Request completed at 2025-04-18T16:53:26.375454 duration: 0.304983 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:26.416279\n",
      "Request completed at 2025-04-18T16:53:26.717222 duration: 0.300943 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:26.750893\n",
      "Request completed at 2025-04-18T16:53:27.017908 duration: 0.267015 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:27.056263\n",
      "Request completed at 2025-04-18T16:53:27.427858 duration: 0.371595 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:27.465262\n",
      "Request completed at 2025-04-18T16:53:27.775802 duration: 0.31054 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:27.809912\n",
      "Request completed at 2025-04-18T16:53:28.107388 duration: 0.297476 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:28.140149\n",
      "Request completed at 2025-04-18T16:53:28.509827 duration: 0.369678 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:28.541833\n",
      "Request completed at 2025-04-18T16:53:28.836843 duration: 0.29501 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:28.861460\n",
      "Request completed at 2025-04-18T16:53:29.111292 duration: 0.249832 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:29.134431\n",
      "Request completed at 2025-04-18T16:53:29.398419 duration: 0.263988 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:29.425606\n",
      "Request completed at 2025-04-18T16:53:29.686257 duration: 0.260651 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:29.711561\n",
      "Request completed at 2025-04-18T16:53:29.999932 duration: 0.288371 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:30.027991\n",
      "Request completed at 2025-04-18T16:53:30.343086 duration: 0.315095 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:30.380216\n",
      "Request completed at 2025-04-18T16:53:30.788676 duration: 0.40846 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:30.821243\n",
      "Request completed at 2025-04-18T16:53:31.160453 duration: 0.33921 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:31.196418\n",
      "Request completed at 2025-04-18T16:53:31.510045 duration: 0.313627 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:31.541149\n",
      "Request completed at 2025-04-18T16:53:31.839499 duration: 0.29835 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:31.867020\n",
      "Request completed at 2025-04-18T16:53:32.164028 duration: 0.297008 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:32.199504\n",
      "Request completed at 2025-04-18T16:53:32.466967 duration: 0.267463 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:32.489473\n",
      "Request completed at 2025-04-18T16:53:32.794279 duration: 0.304806 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:32.863329\n",
      "Request completed at 2025-04-18T16:53:33.107559 duration: 0.24423 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:33.130818\n",
      "Request completed at 2025-04-18T16:53:33.450530 duration: 0.319712 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:33.505499\n",
      "Request completed at 2025-04-18T16:53:33.817714 duration: 0.312215 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:33.853702\n",
      "Request completed at 2025-04-18T16:53:34.177969 duration: 0.324267 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:34.210966\n",
      "Request completed at 2025-04-18T16:53:34.544117 duration: 0.333151 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:34.580254\n",
      "Request completed at 2025-04-18T16:53:34.904835 duration: 0.324581 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:34.934351\n",
      "Request completed at 2025-04-18T16:53:35.197831 duration: 0.26348 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:35.213832\n",
      "Request completed at 2025-04-18T16:53:35.580681 duration: 0.366849 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:35.609757\n",
      "Request completed at 2025-04-18T16:53:35.937722 duration: 0.327965 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:35.969060\n",
      "Request completed at 2025-04-18T16:53:36.217734 duration: 0.248674 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:36.241776\n",
      "Request completed at 2025-04-18T16:53:36.572705 duration: 0.330929 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:36.612989\n",
      "Request completed at 2025-04-18T16:53:36.963917 duration: 0.350928 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:37.000103\n",
      "Request completed at 2025-04-18T16:53:37.296127 duration: 0.296024 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:37.336264\n",
      "Request completed at 2025-04-18T16:53:37.624588 duration: 0.288324 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:37.647311\n",
      "Request completed at 2025-04-18T16:53:37.942620 duration: 0.295309 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:37.978734\n",
      "Request completed at 2025-04-18T16:53:38.326409 duration: 0.347675 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:38.355898\n",
      "Request completed at 2025-04-18T16:53:38.731242 duration: 0.375344 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:38.770092\n",
      "Request completed at 2025-04-18T16:53:39.059260 duration: 0.289168 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:39.081702\n",
      "Request completed at 2025-04-18T16:53:39.396752 duration: 0.31505 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:39.426257\n",
      "Request completed at 2025-04-18T16:53:39.693631 duration: 0.267374 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:39.717479\n",
      "Request completed at 2025-04-18T16:53:39.981220 duration: 0.263741 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:40.001178\n",
      "Request completed at 2025-04-18T16:53:40.303803 duration: 0.302625 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:40.335452\n",
      "Request completed at 2025-04-18T16:53:40.637165 duration: 0.301713 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:40.665414\n",
      "Request completed at 2025-04-18T16:53:40.923344 duration: 0.25793 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:40.946311\n",
      "Request completed at 2025-04-18T16:53:41.241472 duration: 0.295161 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:41.267286\n",
      "Request completed at 2025-04-18T16:53:41.552382 duration: 0.285096 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:41.585323\n",
      "Request completed at 2025-04-18T16:53:41.934870 duration: 0.349547 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:41.968925\n",
      "Request completed at 2025-04-18T16:53:42.294201 duration: 0.325276 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:42.330204\n",
      "Request completed at 2025-04-18T16:53:42.619599 duration: 0.289395 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:42.640973\n",
      "Request completed at 2025-04-18T16:53:42.989773 duration: 0.3488 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:43.019884\n",
      "Request completed at 2025-04-18T16:53:43.307034 duration: 0.28715 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:43.337713\n",
      "Request completed at 2025-04-18T16:53:43.664462 duration: 0.326749 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:43.710898\n",
      "Request completed at 2025-04-18T16:53:43.985104 duration: 0.274206 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:44.006986\n",
      "Request completed at 2025-04-18T16:53:44.251544 duration: 0.244558 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:44.275139\n",
      "Request completed at 2025-04-18T16:53:44.602718 duration: 0.327579 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:44.636610\n",
      "Request completed at 2025-04-18T16:53:44.944306 duration: 0.307696 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:44.969342\n",
      "Request completed at 2025-04-18T16:53:45.309275 duration: 0.339933 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:45.347077\n",
      "Request completed at 2025-04-18T16:53:45.618492 duration: 0.271415 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:45.646396\n",
      "Request completed at 2025-04-18T16:53:45.913651 duration: 0.267255 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:45.938849\n",
      "Request completed at 2025-04-18T16:53:46.239077 duration: 0.300228 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:46.270073\n",
      "Request completed at 2025-04-18T16:53:46.583675 duration: 0.313602 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:46.615716\n",
      "Request completed at 2025-04-18T16:53:46.906412 duration: 0.290696 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:46.935674\n",
      "Request completed at 2025-04-18T16:53:47.274669 duration: 0.338995 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:47.307040\n",
      "Request completed at 2025-04-18T16:53:47.618474 duration: 0.311434 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:47.653113\n",
      "Request completed at 2025-04-18T16:53:47.919013 duration: 0.2659 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:47.937037\n",
      "Request completed at 2025-04-18T16:53:48.207496 duration: 0.270459 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:48.229600\n",
      "Request completed at 2025-04-18T16:53:48.502696 duration: 0.273096 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:48.525745\n",
      "Request completed at 2025-04-18T16:53:48.820307 duration: 0.294562 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:48.848101\n",
      "Request completed at 2025-04-18T16:53:49.150488 duration: 0.302387 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:49.182585\n",
      "Request completed at 2025-04-18T16:53:49.840613 duration: 0.658028 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:49.875749\n",
      "Request completed at 2025-04-18T16:53:50.160766 duration: 0.285017 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:50.195416\n",
      "Request completed at 2025-04-18T16:53:50.446376 duration: 0.25096 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:50.469257\n",
      "Request completed at 2025-04-18T16:53:50.746020 duration: 0.276763 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:50.776864\n",
      "Request completed at 2025-04-18T16:53:51.124685 duration: 0.347821 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:51.159685\n",
      "Request completed at 2025-04-18T16:53:51.474770 duration: 0.315085 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:51.512715\n",
      "Request completed at 2025-04-18T16:53:51.811329 duration: 0.298614 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:51.839561\n",
      "Request completed at 2025-04-18T16:53:52.140590 duration: 0.301029 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:52.169735\n",
      "Request completed at 2025-04-18T16:53:52.530198 duration: 0.360463 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:52.563314\n",
      "Request completed at 2025-04-18T16:53:52.862943 duration: 0.299629 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:52.890769\n",
      "Request completed at 2025-04-18T16:53:53.140775 duration: 0.250006 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:53.169245\n",
      "Request completed at 2025-04-18T16:53:53.444648 duration: 0.275403 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:53.472497\n",
      "Request completed at 2025-04-18T16:53:53.818565 duration: 0.346068 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:53.848737\n",
      "Request completed at 2025-04-18T16:53:54.187043 duration: 0.338306 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:54.219342\n",
      "Request completed at 2025-04-18T16:53:54.595255 duration: 0.375913 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:54.624896\n",
      "Request completed at 2025-04-18T16:53:54.903022 duration: 0.278126 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:54.931361\n",
      "Request completed at 2025-04-18T16:53:55.219144 duration: 0.287783 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:55.256396\n",
      "Request completed at 2025-04-18T16:53:55.503277 duration: 0.246881 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:55.536702\n",
      "Request completed at 2025-04-18T16:53:55.844422 duration: 0.30772 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:55.884167\n",
      "Request completed at 2025-04-18T16:53:56.168797 duration: 0.28463 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:56.204268\n",
      "Request completed at 2025-04-18T16:53:56.512019 duration: 0.307751 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:56.546689\n",
      "Request completed at 2025-04-18T16:53:56.809106 duration: 0.262417 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:56.835375\n",
      "Request completed at 2025-04-18T16:53:57.133923 duration: 0.298548 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:57.162674\n",
      "Request completed at 2025-04-18T16:53:57.423013 duration: 0.260339 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:57.442876\n",
      "Request completed at 2025-04-18T16:53:57.777592 duration: 0.334716 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:57.807745\n",
      "Request completed at 2025-04-18T16:53:58.128884 duration: 0.321139 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:58.161374\n",
      "Request completed at 2025-04-18T16:53:58.429834 duration: 0.26846 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:58.453077\n",
      "Request completed at 2025-04-18T16:53:58.707475 duration: 0.254398 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:58.739142\n",
      "Request completed at 2025-04-18T16:53:59.050105 duration: 0.310963 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:59.090206\n",
      "Request completed at 2025-04-18T16:53:59.359204 duration: 0.268998 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:59.384662\n",
      "Request completed at 2025-04-18T16:53:59.682533 duration: 0.297871 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:53:59.721216\n",
      "Request completed at 2025-04-18T16:54:00.035982 duration: 0.314766 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:00.073664\n",
      "Request completed at 2025-04-18T16:54:00.344191 duration: 0.270527 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:00.367232\n",
      "Request completed at 2025-04-18T16:54:00.721802 duration: 0.35457 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:00.758024\n",
      "Request completed at 2025-04-18T16:54:01.009786 duration: 0.251762 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:01.038440\n",
      "Request completed at 2025-04-18T16:54:01.321992 duration: 0.283552 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:01.349844\n",
      "Request completed at 2025-04-18T16:54:01.639805 duration: 0.289961 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:01.672161\n",
      "Request completed at 2025-04-18T16:54:01.977106 duration: 0.304945 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:02.010806\n",
      "Request completed at 2025-04-18T16:54:02.312603 duration: 0.301797 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:02.345491\n",
      "Request completed at 2025-04-18T16:54:02.627235 duration: 0.281744 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:02.665741\n",
      "Request completed at 2025-04-18T16:54:02.921919 duration: 0.256178 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:02.948878\n",
      "Request completed at 2025-04-18T16:54:03.262091 duration: 0.313213 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:03.289727\n",
      "Request completed at 2025-04-18T16:54:03.555286 duration: 0.265559 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:03.579734\n",
      "Request completed at 2025-04-18T16:54:03.850622 duration: 0.270888 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:03.877360\n",
      "Request completed at 2025-04-18T16:54:04.150924 duration: 0.273564 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:04.180946\n",
      "Request completed at 2025-04-18T16:54:04.477161 duration: 0.296215 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:04.503324\n",
      "Request completed at 2025-04-18T16:54:04.784749 duration: 0.281425 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:04.793114\n",
      "Request completed at 2025-04-18T16:54:05.107461 duration: 0.314347 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:05.144537\n",
      "Request completed at 2025-04-18T16:54:05.497092 duration: 0.352555 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:05.533760\n",
      "Request completed at 2025-04-18T16:54:05.840116 duration: 0.306356 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:05.873468\n",
      "Request completed at 2025-04-18T16:54:06.137334 duration: 0.263866 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:06.161481\n",
      "Request completed at 2025-04-18T16:54:06.432848 duration: 0.271367 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:06.442827\n",
      "Request completed at 2025-04-18T16:54:06.710339 duration: 0.267512 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:06.738471\n",
      "Request completed at 2025-04-18T16:54:07.038626 duration: 0.300155 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:07.069311\n",
      "Request completed at 2025-04-18T16:54:07.408692 duration: 0.339381 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:07.441917\n",
      "Request completed at 2025-04-18T16:54:07.753680 duration: 0.311763 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:07.782131\n",
      "Request completed at 2025-04-18T16:54:08.037883 duration: 0.255752 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:08.060086\n",
      "Request completed at 2025-04-18T16:54:08.321245 duration: 0.261159 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:08.345033\n",
      "Request completed at 2025-04-18T16:54:08.694230 duration: 0.349197 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:08.728637\n",
      "Request completed at 2025-04-18T16:54:09.026497 duration: 0.29786 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:09.050965\n",
      "Request completed at 2025-04-18T16:54:09.363165 duration: 0.3122 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:09.409782\n",
      "Request completed at 2025-04-18T16:54:09.720588 duration: 0.310806 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:09.751658\n",
      "Request completed at 2025-04-18T16:54:10.025263 duration: 0.273605 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:10.048179\n",
      "Request completed at 2025-04-18T16:54:10.376025 duration: 0.327846 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:10.407396\n",
      "Request completed at 2025-04-18T16:54:10.667294 duration: 0.259898 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:10.696002\n",
      "Request completed at 2025-04-18T16:54:10.979400 duration: 0.283398 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:11.005608\n",
      "Request completed at 2025-04-18T16:54:11.268787 duration: 0.263179 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:11.276657\n",
      "Request completed at 2025-04-18T16:54:11.539361 duration: 0.262704 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:11.564921\n",
      "Request completed at 2025-04-18T16:54:11.848588 duration: 0.283667 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:11.877358\n",
      "Request completed at 2025-04-18T16:54:12.169488 duration: 0.29213 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:12.200423\n",
      "Request completed at 2025-04-18T16:54:12.480807 duration: 0.280384 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:12.510721\n",
      "Request completed at 2025-04-18T16:54:12.788066 duration: 0.277345 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:12.811788\n",
      "Request completed at 2025-04-18T16:54:13.132631 duration: 0.320843 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:13.171411\n",
      "Request completed at 2025-04-18T16:54:13.430945 duration: 0.259534 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:13.462468\n",
      "Request completed at 2025-04-18T16:54:13.778103 duration: 0.315635 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:13.786495\n",
      "Request completed at 2025-04-18T16:54:14.053108 duration: 0.266613 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:14.078129\n",
      "Request completed at 2025-04-18T16:54:14.335214 duration: 0.257085 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:14.359748\n",
      "Request completed at 2025-04-18T16:54:14.610734 duration: 0.250986 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:14.637676\n",
      "Request completed at 2025-04-18T16:54:14.899370 duration: 0.261694 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:14.925703\n",
      "Request completed at 2025-04-18T16:54:15.233138 duration: 0.307435 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:15.268674\n",
      "Request completed at 2025-04-18T16:54:15.566616 duration: 0.297942 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:15.596271\n",
      "Request completed at 2025-04-18T16:54:15.908637 duration: 0.312366 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:15.940037\n",
      "Request completed at 2025-04-18T16:54:16.231762 duration: 0.291725 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:16.270348\n",
      "Request completed at 2025-04-18T16:54:16.548552 duration: 0.278204 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:16.578541\n",
      "Request completed at 2025-04-18T16:54:16.834344 duration: 0.255803 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:16.866173\n",
      "Request completed at 2025-04-18T16:54:17.166379 duration: 0.300206 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:17.203517\n",
      "Request completed at 2025-04-18T16:54:17.496118 duration: 0.292601 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:17.514147\n",
      "Request completed at 2025-04-18T16:54:17.773751 duration: 0.259604 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:17.797534\n",
      "Request completed at 2025-04-18T16:54:18.082605 duration: 0.285071 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:18.112658\n",
      "Request completed at 2025-04-18T16:54:18.375560 duration: 0.262902 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:18.403027\n",
      "Request completed at 2025-04-18T16:54:18.663589 duration: 0.260562 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:18.694121\n",
      "Request completed at 2025-04-18T16:54:18.966050 duration: 0.271929 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:18.993262\n",
      "Request completed at 2025-04-18T16:54:19.299442 duration: 0.30618 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:19.333629\n",
      "Request completed at 2025-04-18T16:54:19.633115 duration: 0.299486 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:19.666804\n",
      "Request completed at 2025-04-18T16:54:19.970586 duration: 0.303782 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:20.004181\n",
      "Request completed at 2025-04-18T16:54:20.667778 duration: 0.663597 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:20.710794\n",
      "Request completed at 2025-04-18T16:54:21.035752 duration: 0.324958 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:21.072265\n",
      "Request completed at 2025-04-18T16:54:21.367973 duration: 0.295708 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:21.393014\n",
      "Request completed at 2025-04-18T16:54:21.687717 duration: 0.294703 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:21.719943\n",
      "Request completed at 2025-04-18T16:54:21.987006 duration: 0.267063 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:21.996346\n",
      "Request completed at 2025-04-18T16:54:22.293022 duration: 0.296676 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:22.324013\n",
      "Request completed at 2025-04-18T16:54:22.610946 duration: 0.286933 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:22.639567\n",
      "Request completed at 2025-04-18T16:54:22.921673 duration: 0.282106 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:22.952820\n",
      "Request completed at 2025-04-18T16:54:23.202184 duration: 0.249364 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:23.227543\n",
      "Request completed at 2025-04-18T16:54:23.526507 duration: 0.298964 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:23.558715\n",
      "Request completed at 2025-04-18T16:54:23.820756 duration: 0.262041 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:23.852030\n",
      "Request completed at 2025-04-18T16:54:24.160061 duration: 0.308031 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:24.197126\n",
      "Request completed at 2025-04-18T16:54:24.465088 duration: 0.267962 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:24.494672\n",
      "Request completed at 2025-04-18T16:54:24.756475 duration: 0.261803 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:24.767636\n",
      "Request completed at 2025-04-18T16:54:25.071185 duration: 0.303549 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:25.099931\n",
      "Request completed at 2025-04-18T16:54:25.399051 duration: 0.29912 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:25.434962\n",
      "Request completed at 2025-04-18T16:54:25.738878 duration: 0.303916 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:25.778601\n",
      "Request completed at 2025-04-18T16:54:26.075169 duration: 0.296568 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:26.111242\n",
      "Request completed at 2025-04-18T16:54:26.387581 duration: 0.276339 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:26.421516\n",
      "Request completed at 2025-04-18T16:54:26.754904 duration: 0.333388 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:26.779806\n",
      "Request completed at 2025-04-18T16:54:27.078289 duration: 0.298483 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:27.114358\n",
      "Request completed at 2025-04-18T16:54:27.417005 duration: 0.302647 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:27.451795\n",
      "Request completed at 2025-04-18T16:54:27.739547 duration: 0.287752 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:27.776689\n",
      "Request completed at 2025-04-18T16:54:28.090687 duration: 0.313998 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:28.115430\n",
      "Request completed at 2025-04-18T16:54:28.439413 duration: 0.323983 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:28.472177\n",
      "Request completed at 2025-04-18T16:54:28.784688 duration: 0.312511 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:28.818971\n",
      "Request completed at 2025-04-18T16:54:29.236377 duration: 0.417406 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:29.283934\n",
      "Request completed at 2025-04-18T16:54:29.582791 duration: 0.298857 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:29.617420\n",
      "Request completed at 2025-04-18T16:54:29.908458 duration: 0.291038 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:29.936424\n",
      "Request completed at 2025-04-18T16:54:30.217203 duration: 0.280779 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:30.248590\n",
      "Request completed at 2025-04-18T16:54:30.545987 duration: 0.297397 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:30.589723\n",
      "Request completed at 2025-04-18T16:54:30.849276 duration: 0.259553 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:30.860553\n",
      "Request completed at 2025-04-18T16:54:31.244607 duration: 0.384054 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:31.279622\n",
      "Request completed at 2025-04-18T16:54:32.111971 duration: 0.832349 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:32.149495\n",
      "Request completed at 2025-04-18T16:54:32.439359 duration: 0.289864 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:32.478049\n",
      "Request completed at 2025-04-18T16:54:32.818921 duration: 0.340872 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:32.851076\n",
      "Request completed at 2025-04-18T16:54:33.108209 duration: 0.257133 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:33.131275\n",
      "Request completed at 2025-04-18T16:54:33.399409 duration: 0.268134 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:33.426245\n",
      "Request completed at 2025-04-18T16:54:33.681174 duration: 0.254929 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:33.702916\n",
      "Request completed at 2025-04-18T16:54:33.949365 duration: 0.246449 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:33.974287\n",
      "Request completed at 2025-04-18T16:54:34.256941 duration: 0.282654 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:34.283908\n",
      "Request completed at 2025-04-18T16:54:34.549944 duration: 0.266036 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:34.579281\n",
      "Request completed at 2025-04-18T16:54:34.857934 duration: 0.278653 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:34.890448\n",
      "Request completed at 2025-04-18T16:54:35.246261 duration: 0.355813 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:35.279807\n",
      "Request completed at 2025-04-18T16:54:35.612341 duration: 0.332534 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:35.644815\n",
      "Request completed at 2025-04-18T16:54:35.942051 duration: 0.297236 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:35.973500\n",
      "Request completed at 2025-04-18T16:54:36.347439 duration: 0.373939 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:36.383165\n",
      "Request completed at 2025-04-18T16:54:36.742894 duration: 0.359729 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:36.779977\n",
      "Request completed at 2025-04-18T16:54:37.061962 duration: 0.281985 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:37.096306\n",
      "Request completed at 2025-04-18T16:54:37.399218 duration: 0.302912 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:37.439080\n",
      "Request completed at 2025-04-18T16:54:37.696052 duration: 0.256972 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:37.719546\n",
      "Request completed at 2025-04-18T16:54:37.987877 duration: 0.268331 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:38.013782\n",
      "Request completed at 2025-04-18T16:54:38.272409 duration: 0.258627 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:38.296199\n",
      "Request completed at 2025-04-18T16:54:38.643752 duration: 0.347553 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:38.678904\n",
      "Request completed at 2025-04-18T16:54:38.949517 duration: 0.270613 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:38.976773\n",
      "Request completed at 2025-04-18T16:54:39.250372 duration: 0.273599 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:39.279555\n",
      "Request completed at 2025-04-18T16:54:39.554363 duration: 0.274808 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:39.581414\n",
      "Request completed at 2025-04-18T16:54:39.860924 duration: 0.27951 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:39.886922\n",
      "Request completed at 2025-04-18T16:54:40.182751 duration: 0.295829 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:40.218647\n",
      "Request completed at 2025-04-18T16:54:40.465891 duration: 0.247244 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:40.489585\n",
      "Request completed at 2025-04-18T16:54:40.833545 duration: 0.34396 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:40.871453\n",
      "Request completed at 2025-04-18T16:54:41.135642 duration: 0.264189 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:41.159471\n",
      "Request completed at 2025-04-18T16:54:41.444652 duration: 0.285181 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:41.470233\n",
      "Request completed at 2025-04-18T16:54:41.749534 duration: 0.279301 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:41.777334\n",
      "Request completed at 2025-04-18T16:54:42.102826 duration: 0.325492 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:42.137958\n",
      "Request completed at 2025-04-18T16:54:42.402567 duration: 0.264609 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "KeyError: 'PmZQCMHU8cAhIdZshFuipCPi' - The expected key wasn't found in the API response.\n",
      "Starting request at 2025-04-18 16:54:42.411314\n",
      "Request completed at 2025-04-18T16:54:42.667917 duration: 0.256603 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n",
      "Starting request at 2025-04-18 16:54:42.689887\n",
      "Request completed at 2025-04-18T16:54:42.938873 duration: 0.248986 seconds\n",
      "http status code: 200\n",
      "Testing whether it is valid json...\n",
      "JSON successfully loadded into variable `json_response`\n"
     ]
    }
   ],
   "source": [
    "schedule = match_notifications_to_schedule(\"notification_dates_log.csv\")\n",
    "schedule.to_csv(\"notification_dates_log_with_deliveries.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc9895-4253-4639-8b1e-7642933696e5",
   "metadata": {},
   "source": [
    "##### Part 3d: Identify Unexpected Submissions\n",
    "\n",
    "Finally, we can cross-reference the submissions log against the notifications log to find two kinds of unexpected surveys as mentioned above:\n",
    "1. Submissions outside of the expected schedules\n",
    "2. Multiple submissions in one notification period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b28e81f-b3c4-4d2a-8c2a-ed54410dec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_answers_to_notifications(notifications_file, answers_file, counts_file):\n",
    "    '''\n",
    "    Inputs:\n",
    "        notifications_file: the csv file containing the expected and delivered notification schedule, as generated in Parts 3b/3c\n",
    "        answers_file: the csv file containing the answer submission log, as generated in Part 3a\n",
    "        counts_file: the csv file containing the submission counts for each participant\n",
    "    Output:\n",
    "        notification_log: a df containing everything in the notification_dates_file_with_deliveries with an additional\n",
    "        column for number of submissions within each notification window\n",
    "        counts: a df that adds counts of outside and double submissions to the counts file\n",
    "    Behavior:\n",
    "        This function cross-checks the two input logs and flags any unexpected submissions\n",
    "    '''\n",
    "    # Read the notification log csv\n",
    "    schedule = pd.read_csv(notifications_file)\n",
    "    schedule['DeliveredUTC'] = schedule['DeliveredUTC'].apply(lambda x: pd.to_datetime(x))\n",
    "    schedule['TruncatedUTC'] = schedule['TruncatedUTC'].apply(lambda x: pd.to_datetime(x))\n",
    "    schedule['SurveysSubmitted'] = 0\n",
    "\n",
    "    # Read the answers log csv\n",
    "    answers = pd.read_csv(answers_file)\n",
    "\n",
    "    # Read the final counts csv\n",
    "    counts = pd.read_csv(counts_file)\n",
    "    counts[\"DoubleSubmissions\"] = 0\n",
    "    counts[\"OutsideSubmissions\"] = 0\n",
    "    counts[\"CheckManually\"] = False\n",
    "\n",
    "    # Create a list for the filtered answers log\n",
    "    filtered_answers = []\n",
    "\n",
    "    outside, extra = 0,0\n",
    "\n",
    "    # Iterate each row of the answers log\n",
    "    for index, row in answers.iterrows():\n",
    "        # Extract the Beiwe ID, timestamp and file path\n",
    "        timestamp = pd.Timestamp(row['TimestampUTC'])\n",
    "        date = row['Date']\n",
    "        beiwe_id = row['BeiweID']\n",
    "        file_path = row['FilePath']\n",
    "\n",
    "        # Look for notification delibery corresponding to the answer submission\n",
    "        mask = (\n",
    "            (schedule['BeiweID'] == beiwe_id) &\n",
    "            (schedule['DeliveredUTC'] < timestamp) & \n",
    "            (schedule['TruncatedUTC'] > timestamp)\n",
    "        )\n",
    "\n",
    "        # Indicator whether this is a valid row\n",
    "        valid_row = True\n",
    "        \n",
    "        if schedule.loc[mask].empty:\n",
    "            if not schedule.loc[(schedule['BeiweID'] == beiwe_id) & (schedule['CalculatedDate'] == date)].empty:\n",
    "                counts.loc[counts['BeiweID'] == beiwe_id, 'CheckManually'] = True\n",
    "                print(f\"[CHECK MANUALLY] Issue with notification history: {file_path}\")\n",
    "            else:\n",
    "                \n",
    "                counts.loc[counts['BeiweID'] == beiwe_id, 'OutsideSubmissions'] += 1\n",
    "                print(f\"Submission outside of diary period: {file_path}\")\n",
    "            outside += 1\n",
    "        else:\n",
    "            burst = schedule.loc[mask, 'Burst'].iloc[0]\n",
    "            \n",
    "        schedule.loc[mask, 'SurveysSubmitted'] = schedule.loc[mask, 'SurveysSubmitted'] + 1\n",
    "\n",
    "        if (schedule.loc[mask, 'SurveysSubmitted'] > 1).any():\n",
    "            valid_row = False\n",
    "            counts.loc[counts['BeiweID'] == beiwe_id, 'DoubleSubmissions'] += 1\n",
    "            print(f\"Unexpected extra submission: {file_path}\")\n",
    "            extra += 1\n",
    "\n",
    "        if valid_row:\n",
    "            row['Burst'] = burst\n",
    "            filtered_answers.append(row)\n",
    "\n",
    "    print(f\"Total submissions outside of diary periods: {outside}\")\n",
    "    print(f\"Total submission periods (days) with multiple submissions: {extra}\")\n",
    "    filtered_answers = pd.DataFrame(filtered_answers, columns=['BeiweID','Date','TimestampUTC','FilePath','Burst'])\n",
    "    return schedule, counts, filtered_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f42c4aa-da61-4de5-9563-52ee454dd6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission outside of diary period: raw_data/11hfsajc/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-02 14_31_35+00_00.csv\n",
      "Submission outside of diary period: raw_data/1bllhfi7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-01 19_40_51+00_00.csv\n",
      "Submission outside of diary period: raw_data/1bllhfi7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-02 00_57_30+00_00.csv\n",
      "Submission outside of diary period: raw_data/1czziou5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-17 04_35_05+00_00.csv\n",
      "Unexpected extra submission: raw_data/1ib9r56g/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-22 00_34_11+00_00.csv\n",
      "Submission outside of diary period: raw_data/1ib9r56g/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-03 21_05_03+00_00.csv\n",
      "Submission outside of diary period: raw_data/1sshhk6u/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-04 23_25_22+00_00.csv\n",
      "Submission outside of diary period: raw_data/1w8gybjj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-25 05_42_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/1w8gybjj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-23 18_12_13+00_00.csv\n",
      "Submission outside of diary period: raw_data/24yg3qzn/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-09 01_53_18+00_00.csv\n",
      "Submission outside of diary period: raw_data/24yg3qzn/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-10 02_28_33+00_00.csv\n",
      "Submission outside of diary period: raw_data/33vc2l25/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-28 14_45_37+00_00.csv\n",
      "Submission outside of diary period: raw_data/49mwcsiz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-10 02_50_43+00_00.csv\n",
      "Submission outside of diary period: raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-26 15_14_43+00_00.csv\n",
      "Submission outside of diary period: raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-09 13_29_17+00_00.csv\n",
      "Submission outside of diary period: raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-16 12_54_03+00_00.csv\n",
      "Submission outside of diary period: raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-25 16_30_57+00_00.csv\n",
      "Submission outside of diary period: raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-24 16_41_58+00_00.csv\n",
      "Submission outside of diary period: raw_data/4ggpbwfj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-23 17_42_20+00_00.csv\n",
      "Submission outside of diary period: raw_data/4qg4ghee/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-26 16_53_09+00_00.csv\n",
      "Unexpected extra submission: raw_data/4qg4ghee/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-18 14_26_42+00_00.csv\n",
      "Submission outside of diary period: raw_data/4qg4ghee/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-25 23_32_17+00_00.csv\n",
      "Submission outside of diary period: raw_data/4sl276dm/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-19 18_02_54+00_00.csv\n",
      "[CHECK MANUALLY] Issue with notification history: raw_data/5tj2bcfz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-15 13_37_36+00_00.csv\n",
      "Submission outside of diary period: raw_data/5xgimlg2/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-02 01_45_19+00_00.csv\n",
      "Submission outside of diary period: raw_data/5zensrjc/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-28 17_43_31+00_00.csv\n",
      "Submission outside of diary period: raw_data/6c5fwr29/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-12 04_06_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/6c5fwr29/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-15 18_21_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/6c5fwr29/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-22 21_21_34+00_00.csv\n",
      "Submission outside of diary period: raw_data/6c5fwr29/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-06 19_58_39+00_00.csv\n",
      "Submission outside of diary period: raw_data/6dkw2zd9/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-19 19_28_20+00_00.csv\n",
      "Submission outside of diary period: raw_data/6j1lnpb6/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-09 23_37_34+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-02 20_15_15+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-05 17_32_24+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-10 00_08_57+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-10 19_51_05+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-12 16_07_30+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-14 16_11_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-15 15_39_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-18 18_43_18+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-19 13_14_26+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-08 04_53_35+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-13 17_44_43+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-20 18_15_37+00_00.csv\n",
      "Submission outside of diary period: raw_data/6qmqfkeq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-02 12_23_03+00_00.csv\n",
      "Submission outside of diary period: raw_data/6uqywzdm/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-04 01_39_43+00_00.csv\n",
      "Submission outside of diary period: raw_data/6uqywzdm/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-04 03_07_25+00_00.csv\n",
      "Submission outside of diary period: raw_data/6yq7anur/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-19 23_15_38+00_00.csv\n",
      "Submission outside of diary period: raw_data/7wx553qy/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-05 17_07_42+00_00.csv\n",
      "Submission outside of diary period: raw_data/81jervii/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-03 18_37_18+00_00.csv\n",
      "Submission outside of diary period: raw_data/81jervii/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-03 13_38_59+00_00.csv\n",
      "Submission outside of diary period: raw_data/81jervii/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-21 17_23_43+00_00.csv\n",
      "Submission outside of diary period: raw_data/89v1avmz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-27 23_37_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/89v1avmz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-28 18_52_05+00_00.csv\n",
      "Submission outside of diary period: raw_data/8hszphf9/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-03 19_07_42+00_00.csv\n",
      "Submission outside of diary period: raw_data/8rx3kyrz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-03 14_46_37+00_00.csv\n",
      "[CHECK MANUALLY] Issue with notification history: raw_data/8wcv79ly/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-01 13_50_44+00_00.csv\n",
      "Submission outside of diary period: raw_data/9ehmj2fz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-18 18_26_51+00_00.csv\n",
      "Submission outside of diary period: raw_data/a2wiazls/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-10-01 04_21_37+00_00.csv\n",
      "Unexpected extra submission: raw_data/a2wiazls/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-26 04_13_22+00_00.csv\n",
      "Submission outside of diary period: raw_data/a2wiazls/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-31 00_26_04+00_00.csv\n",
      "Submission outside of diary period: raw_data/a3k59n11/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-24 07_28_41+00_00.csv\n",
      "Unexpected extra submission: raw_data/a4plymya/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-24 21_33_00+00_00.csv\n",
      "Unexpected extra submission: raw_data/a4plymya/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-30 13_11_22+00_00.csv\n",
      "Submission outside of diary period: raw_data/acxdh2cq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-02 22_29_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/acxdh2cq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-06 14_38_56+00_00.csv\n",
      "Submission outside of diary period: raw_data/adwnelex/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-29 00_09_07+00_00.csv\n",
      "Submission outside of diary period: raw_data/adwnelex/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-05 00_56_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/ag5wdmi3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-08 22_56_11+00_00.csv\n",
      "Submission outside of diary period: raw_data/ajqv1ibq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-22 12_59_42+00_00.csv\n",
      "Submission outside of diary period: raw_data/be3smgzk/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-25 01_07_11+00_00.csv\n",
      "Submission outside of diary period: raw_data/be3smgzk/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-21 01_40_47+00_00.csv\n",
      "Submission outside of diary period: raw_data/bebinp4t/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-18 06_50_04+00_00.csv\n",
      "Submission outside of diary period: raw_data/bvavxgux/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-04 16_29_38+00_00.csv\n",
      "Unexpected extra submission: raw_data/cbh8yze7/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-21 02_11_46+00_00.csv\n",
      "Submission outside of diary period: raw_data/cshvodgb/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-10-17 04_08_45+00_00.csv\n",
      "Submission outside of diary period: raw_data/cshvodgb/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-01 04_54_14+00_00.csv\n",
      "Submission outside of diary period: raw_data/cshvodgb/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-27 00_36_55+00_00.csv\n",
      "Submission outside of diary period: raw_data/ct2nr49d/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-25 18_12_12+00_00.csv\n",
      "Unexpected extra submission: raw_data/d188d2ib/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-16 10_45_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/dlio244z/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-16 21_28_52+00_00.csv\n",
      "Submission outside of diary period: raw_data/dlio244z/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-17 22_45_57+00_00.csv\n",
      "Unexpected extra submission: raw_data/dpvsqpqf/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-19 17_04_02+00_00.csv\n",
      "Submission outside of diary period: raw_data/e25wbu6o/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-06 16_21_46+00_00.csv\n",
      "Submission outside of diary period: raw_data/elmsldp5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-24 03_11_52+00_00.csv\n",
      "Submission outside of diary period: raw_data/elspw6qp/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-03 05_42_16+00_00.csv\n",
      "Submission outside of diary period: raw_data/eq3srjdy/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-23 18_36_31+00_00.csv\n",
      "Submission outside of diary period: raw_data/f1xqtpld/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-09 14_02_11+00_00.csv\n",
      "Unexpected extra submission: raw_data/fhjswy1u/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-16 04_17_02+00_00.csv\n",
      "Submission outside of diary period: raw_data/fhjswy1u/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-21 00_07_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/fk2v9sst/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-26 21_00_46+00_00.csv\n",
      "Unexpected extra submission: raw_data/frf7ayr5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-05 16_33_17+00_00.csv\n",
      "Submission outside of diary period: raw_data/frf7ayr5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-22 22_09_06+00_00.csv\n",
      "Submission outside of diary period: raw_data/frf7ayr5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-10 23_48_20+00_00.csv\n",
      "Submission outside of diary period: raw_data/gq4s82qs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-06 14_03_23+00_00.csv\n",
      "Submission outside of diary period: raw_data/gq4s82qs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-07 18_30_10+00_00.csv\n",
      "Submission outside of diary period: raw_data/gq4s82qs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-10 14_48_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/gq4s82qs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-28 02_46_52+00_00.csv\n",
      "Submission outside of diary period: raw_data/gq4s82qs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-23 00_36_28+00_00.csv\n",
      "Submission outside of diary period: raw_data/gq4s82qs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-26 02_19_09+00_00.csv\n",
      "Unexpected extra submission: raw_data/h323v5fd/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-29 14_28_30+00_00.csv\n",
      "Submission outside of diary period: raw_data/h3pocaum/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-13 18_10_41+00_00.csv\n",
      "Submission outside of diary period: raw_data/hoqafprw/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-11 19_29_50+00_00.csv\n",
      "Submission outside of diary period: raw_data/hoqafprw/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-03 14_03_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/hure3dcb/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-10 19_42_02+00_00.csv\n",
      "Unexpected extra submission: raw_data/hxm635ew/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-04 13_59_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-10 14_04_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-13 14_02_44+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-14 14_04_56+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-15 21_36_30+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-17 01_12_48+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-18 14_20_46+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-20 16_07_23+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-05 17_40_34+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-06 14_13_12+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-07 14_21_20+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-08 16_51_32+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-09 18_52_42+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-10 21_56_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-11 16_32_02+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-12 14_12_56+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-16 22_42_46+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-17 22_00_33+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-19 01_19_23+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-19 14_03_32+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-02 18_19_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-09 14_06_41+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-10 18_23_20+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-11 13_06_10+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-12 13_09_15+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-15 01_23_12+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-15 13_27_02+00_00.csv\n",
      "Submission outside of diary period: raw_data/iadeeya3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-11 20_06_53+00_00.csv\n",
      "Unexpected extra submission: raw_data/iealausr/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-30 21_20_15+00_00.csv\n",
      "Unexpected extra submission: raw_data/j96jck8o/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-23 21_13_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/j96jck8o/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-18 01_52_10+00_00.csv\n",
      "Submission outside of diary period: raw_data/jeipst7r/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-16 13_46_30+00_00.csv\n",
      "Submission outside of diary period: raw_data/ji6kggnh/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-06 15_59_44+00_00.csv\n",
      "Unexpected extra submission: raw_data/js9dzj4m/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-04 17_02_53+00_00.csv\n",
      "Submission outside of diary period: raw_data/js9dzj4m/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-16 17_02_48+00_00.csv\n",
      "Submission outside of diary period: raw_data/juqyd3vu/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-11 13_59_27+00_00.csv\n",
      "Unexpected extra submission: raw_data/k98ncfwh/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-29 13_15_24+00_00.csv\n",
      "Submission outside of diary period: raw_data/kb5mxovq/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-13 15_04_49+00_00.csv\n",
      "Submission outside of diary period: raw_data/km698xy3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-06 23_29_07+00_00.csv\n",
      "Submission outside of diary period: raw_data/km698xy3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-10 23_50_51+00_00.csv\n",
      "Submission outside of diary period: raw_data/lrmrdr3y/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-08 17_58_42+00_00.csv\n",
      "Submission outside of diary period: raw_data/lrmrdr3y/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-09 17_44_13+00_00.csv\n",
      "Submission outside of diary period: raw_data/ly7qnqkp/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-16 16_10_46+00_00.csv\n",
      "Submission outside of diary period: raw_data/ly7qnqkp/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-16 16_45_57+00_00.csv\n",
      "Submission outside of diary period: raw_data/m58fpko8/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-26 22_11_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/mhwnmw12/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-05 02_54_23+00_00.csv\n",
      "[CHECK MANUALLY] Issue with notification history: raw_data/mhwnmw12/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-21 13_05_57+00_00.csv\n",
      "Submission outside of diary period: raw_data/mhwnmw12/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-29 20_44_03+00_00.csv\n",
      "Submission outside of diary period: raw_data/mhwnmw12/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-04 16_02_00+00_00.csv\n",
      "Submission outside of diary period: raw_data/mhwnmw12/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-04 01_03_38+00_00.csv\n",
      "Submission outside of diary period: raw_data/mjumw9e3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-19 05_11_45+00_00.csv\n",
      "Submission outside of diary period: raw_data/mjumw9e3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-13 00_54_14+00_00.csv\n",
      "Submission outside of diary period: raw_data/mmjjqemc/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-10 05_25_57+00_00.csv\n",
      "Submission outside of diary period: raw_data/mrfmuhvj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-23 14_32_07+00_00.csv\n",
      "Submission outside of diary period: raw_data/msj113qe/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-13 03_01_39+00_00.csv\n",
      "Submission outside of diary period: raw_data/mt9ldako/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-09 18_07_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/ng7mkyit/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-09 14_17_05+00_00.csv\n",
      "Submission outside of diary period: raw_data/ng7mkyit/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-11 20_38_32+00_00.csv\n",
      "Submission outside of diary period: raw_data/nm6ahjsz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-18 14_26_15+00_00.csv\n",
      "Unexpected extra submission: raw_data/o72ugjhg/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-25 18_05_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/o72ugjhg/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-02 21_56_47+00_00.csv\n",
      "Unexpected extra submission: raw_data/o93nynue/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-23 18_07_16+00_00.csv\n",
      "Submission outside of diary period: raw_data/o93nynue/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-01-27 14_44_25+00_00.csv\n",
      "Submission outside of diary period: raw_data/ooqyppkj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-14 22_19_15+00_00.csv\n",
      "Submission outside of diary period: raw_data/opjjmv42/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-18 11_39_57+00_00.csv\n",
      "Submission outside of diary period: raw_data/oz7nz5qd/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-15 21_27_53+00_00.csv\n",
      "Submission outside of diary period: raw_data/oz7nz5qd/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-16 16_56_10+00_00.csv\n",
      "Unexpected extra submission: raw_data/peb38bk5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-06 02_47_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/pewlnfhy/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-04 03_45_04+00_00.csv\n",
      "Submission outside of diary period: raw_data/q1m8cls3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-15 22_24_12+00_00.csv\n",
      "Submission outside of diary period: raw_data/q1m8cls3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-10-14 21_39_31+00_00.csv\n",
      "Submission outside of diary period: raw_data/q1m8cls3/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-26 00_31_36+00_00.csv\n",
      "Submission outside of diary period: raw_data/qtrph1ch/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-24 17_45_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/qtrph1ch/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-23 18_11_54+00_00.csv\n",
      "Submission outside of diary period: raw_data/qwpf5ivi/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-29 17_04_07+00_00.csv\n",
      "Submission outside of diary period: raw_data/qwpf5ivi/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-29 17_05_58+00_00.csv\n",
      "Submission outside of diary period: raw_data/qwpf5ivi/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-30 18_18_56+00_00.csv\n",
      "Submission outside of diary period: raw_data/qxgs5tdn/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-02 02_09_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-18 16_42_49+00_00.csv\n",
      "Submission outside of diary period: raw_data/ra5aq9d5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-12 01_37_19+00_00.csv\n",
      "Submission outside of diary period: raw_data/ra5aq9d5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-12 23_13_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/ra5aq9d5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-14 04_53_36+00_00.csv\n",
      "Submission outside of diary period: raw_data/ra5aq9d5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-21 23_22_18+00_00.csv\n",
      "Submission outside of diary period: raw_data/ra5aq9d5/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-03 22_09_48+00_00.csv\n",
      "Submission outside of diary period: raw_data/rcmc2dws/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-16 13_04_36+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-03 23_07_03+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-04 14_11_12+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-05 17_15_05+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-06 14_09_19+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-07 14_57_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-09 04_04_18+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-10 12_00_00+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-10 22_16_43+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-12 12_07_17+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-12 17_32_20+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-15 03_23_48+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-16 13_51_52+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-17 12_16_16+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-03 12_46_12+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-07 12_59_44+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-09 13_49_13+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-18 16_42_49+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-02 19_33_09+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-04 17_38_22+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-06 09_45_10+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-07 21_36_06+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-11 09_16_37+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-11 23_01_14+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-13 01_33_53+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-14 09_06_06+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-14 22_55_35+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-16 03_40_16+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-03 21_34_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-05 07_03_07+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-06 02_10_14+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-06 20_34_57+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-08 04_20_30+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-08 20_36_50+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-10 06_04_17+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-11 18_41_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-14 06_12_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/r8y71qnz/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-17 13_37_24+00_00.csv\n",
      "Submission outside of diary period: raw_data/reo62ltw/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-12 16_34_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/rprigneb/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-23 18_53_21+00_00.csv\n",
      "Unexpected extra submission: raw_data/rstokk1a/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-06-16 18_25_41+00_00.csv\n",
      "Unexpected extra submission: raw_data/rz1t9mpt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-10-20 20_33_02+00_00.csv\n",
      "Submission outside of diary period: raw_data/rz1t9mpt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-14 23_22_09+00_00.csv\n",
      "Submission outside of diary period: raw_data/sfctppup/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-29 17_50_32+00_00.csv\n",
      "Submission outside of diary period: raw_data/sfctppup/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-29 14_26_28+00_00.csv\n",
      "Unexpected extra submission: raw_data/sfih1cjt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-04 13_43_40+00_00.csv\n",
      "Submission outside of diary period: raw_data/sfih1cjt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-14 14_04_06+00_00.csv\n",
      "Submission outside of diary period: raw_data/sfih1cjt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-13 02_48_59+00_00.csv\n",
      "Submission outside of diary period: raw_data/slgm2rxi/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-10-22 04_31_28+00_00.csv\n",
      "Submission outside of diary period: raw_data/slgm2rxi/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-17 05_24_51+00_00.csv\n",
      "Unexpected extra submission: raw_data/tbagwbl9/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-16 18_18_54+00_00.csv\n",
      "Submission outside of diary period: raw_data/ter7pxoe/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-04 04_48_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/tkwn9148/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-15 14_04_53+00_00.csv\n",
      "Submission outside of diary period: raw_data/tkwn9148/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-30 07_40_32+00_00.csv\n",
      "Submission outside of diary period: raw_data/tkwn9148/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-04 22_53_08+00_00.csv\n",
      "Submission outside of diary period: raw_data/tl57unkl/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-06 00_21_01+00_00.csv\n",
      "Submission outside of diary period: raw_data/tl57unkl/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-08 13_04_30+00_00.csv\n",
      "Submission outside of diary period: raw_data/tl57unkl/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-18 18_23_29+00_00.csv\n",
      "[CHECK MANUALLY] Issue with notification history: raw_data/tpr4b4hj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-09-02 19_21_11+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-18 22_25_29+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-18 22_42_05+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-23 14_14_51+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-06 16_23_59+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-09 19_07_14+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-10 21_33_04+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-13 15_49_28+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-15 17_22_14+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-07 14_08_53+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-08 14_00_55+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-09 22_14_40+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-11 13_07_48+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-13 16_27_21+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-14 19_52_51+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-03-16 16_01_35+00_00.csv\n",
      "Submission outside of diary period: raw_data/txo6lahs/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-05-14 17_25_37+00_00.csv\n",
      "[CHECK MANUALLY] Issue with notification history: raw_data/uewaotso/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-26 03_40_12+00_00.csv\n",
      "Submission outside of diary period: raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-06 14_04_25+00_00.csv\n",
      "Submission outside of diary period: raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-07 18_18_03+00_00.csv\n",
      "Submission outside of diary period: raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-10 19_59_10+00_00.csv\n",
      "Submission outside of diary period: raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-11-27 14_44_34+00_00.csv\n",
      "Submission outside of diary period: raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2023-12-10 20_06_00+00_00.csv\n",
      "Submission outside of diary period: raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-04-09 20_25_04+00_00.csv\n",
      "Submission outside of diary period: raw_data/uiz2mt3n/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-26 21_23_17+00_00.csv\n",
      "Unexpected extra submission: raw_data/up1qefml/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-29 19_28_34+00_00.csv\n",
      "Submission outside of diary period: raw_data/vis6vd5c/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-08-11 20_18_13+00_00.csv\n",
      "Submission outside of diary period: raw_data/vis6vd5c/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-05 00_34_26+00_00.csv\n",
      "Submission outside of diary period: raw_data/vis6vd5c/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-11-11 14_29_52+00_00.csv\n",
      "Submission outside of diary period: raw_data/wit5qifi/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-03-17 16_27_04+00_00.csv\n",
      "Unexpected extra submission: raw_data/wxokpxg8/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-07 01_30_01+00_00.csv\n",
      "Unexpected extra submission: raw_data/wxokpxg8/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-07 02_08_22+00_00.csv\n",
      "Submission outside of diary period: raw_data/xa6p5fzt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-23 16_18_50+00_00.csv\n",
      "Unexpected extra submission: raw_data/xgrb4ude/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-15 23_57_37+00_00.csv\n",
      "Unexpected extra submission: raw_data/xgrb4ude/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-17 22_08_41+00_00.csv\n",
      "Submission outside of diary period: raw_data/xigutsxt/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-23 16_39_16+00_00.csv\n",
      "Submission outside of diary period: raw_data/xiwxow16/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-29 21_56_49+00_00.csv\n",
      "Submission outside of diary period: raw_data/y5vxfnxj/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-12-30 23_00_31+00_00.csv\n",
      "Submission outside of diary period: raw_data/yd8makxv/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-01-18 22_51_55+00_00.csv\n",
      "Submission outside of diary period: raw_data/yo6y8jnx/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2025-02-12 03_19_17+00_00.csv\n",
      "Submission outside of diary period: raw_data/zmqqnw91/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-07-15 15_00_09+00_00.csv\n",
      "Submission outside of diary period: raw_data/ztcichn8/survey_answers/PmZQCMHU8cAhIdZshFuipCPi/2024-02-03 16_40_39+00_00.csv\n",
      "Total submissions outside of diary periods: 261\n",
      "Total submission periods (days) with multiple submissions: 28\n"
     ]
    }
   ],
   "source": [
    "notifications_file = \"notification_dates_log_with_deliveries.csv\"\n",
    "answers_file = \"answers_log_full.csv\"\n",
    "counts_file = \"final_counts.csv\"\n",
    "schedule, counts, answers = match_answers_to_notifications(notifications_file, answers_file, counts_file)\n",
    "schedule.to_csv(\"notification_dates_log_with_deliveries_and_submissions.csv\", index = False)\n",
    "\n",
    "answers = answers[['BeiweID','Date','Burst','TimestampUTC','FilePath']]\n",
    "answers.to_csv(\"answers_log_filtered.csv\", index = False)\n",
    "\n",
    "counts = counts.sort_values(by=['LastSurvey', 'BeiweID'])\n",
    "counts = counts[['BeiweID','EnrollmentDate', 'LastSurvey', 'SurveyCount', 'DoubleSubmissions', 'OutsideSubmissions', 'CheckManually']]\n",
    "counts.to_csv(\"final_counts.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c0098-acad-4573-bcb6-3a10e6572a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
